<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deploying gitea into kubernetes with custom domain | chown u+r mind</title>
<meta name=keywords content="Kubernetes,giea,dns,helm,proxmox,bind9"><meta name=description content="Introduction Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers."><meta name=author content="Me"><link rel=canonical href=//localhost:1313/posts/deploy-gitea-k8s/><meta name=google-site-verification content="G-XPKK3C6HL0"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=//localhost:1313/posts/deploy-gitea-k8s/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Deploying gitea into kubernetes with custom domain"><meta property="og:description" content="Introduction Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers."><meta property="og:type" content="article"><meta property="og:url" content="//localhost:1313/posts/deploy-gitea-k8s/"><meta property="og:image" content="//localhost:1313/img/deploy_gitea.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-20T16:12:38+01:00"><meta property="article:modified_time" content="2023-05-20T16:12:38+01:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//localhost:1313/img/deploy_gitea.jpg"><meta name=twitter:title content="Deploying gitea into kubernetes with custom domain"><meta name=twitter:description content="Introduction Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"//localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Deploying gitea into kubernetes with custom domain","item":"//localhost:1313/posts/deploy-gitea-k8s/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deploying gitea into kubernetes with custom domain","name":"Deploying gitea into kubernetes with custom domain","description":"Introduction Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers.","keywords":["Kubernetes","giea","dns","helm","proxmox","bind9"],"articleBody":"Introduction Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers.\nPrerequisite * kubernetes cluster * external server(S3,NFS) for dynamic provisioning * metallb installed Create PVC for NFS Server With the help of Proxmox, I created a VM and configured it as an NFS server on 192.168.1.109. To use this server in our Kubernetes cluster, we need to create a StorageClass and then create a PVC that points to that class so pods can use it.\n1 2 3 4 5 helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ --create-namespace \\ --namespace nfs-provisioner \\ --set nfs.server=192.168.1.109 \\ --set nfs.path=/srv/public/nfs Then we create a PVC, linking it to the storageClassName:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nfs-test labels: storage.k8s.io/name: nfs storage.k8s.io/part-of: kubernetes-complete-reference spec: accessModes: - ReadWriteMany storageClassName: nfs-client resources: requests: storage: 15Gi If we want the deployment to store its volume in NFS, we define volumes with the argument persistentVolumeClaim = nfs-test. Here is an example:\n1 2 3 4 5 6 7 8 9 10 apiVersion: v1 kind: Pod metadata: name: task-pv-pod spec: volumes: - name: task-pv-storage persistentVolumeClaim: claimName: nfs-test ... Deploy Gitea + PostgreSQL + Redis To facilitate deploying resources into Kubernetes, we use Helm. With one command and changing a few values, we can deploy our resources. Before deploying, when I was reading the Gitea chart, I noticed Gitea requires PostgreSQL and Redis to be deployed alongside it to save its configs and states.\nSo let’s create a file ‘values-gitea.yaml’ and add the default chart values.\nThen change the following values:\n1 2 3 4 5 6 7 8 9 persistence: create: false claimName: nfs-test postgresql-ha: enabled: false postgresql: enabled: true I disabled the deployment of Postgres-HA because I didn’t need it for my use case. However, if you’re deploying for your organization where multiple users are pushing and pulling, you may keep it enabled.\nNow to deploy the Helm release with the modifications, run:\n1 helm install gitea gitea-charts/gitea --values values-gitea.yaml NOTE: You need a cluster with an internet connection to pull the Docker images.\nNOTE: If you don’t specify the namespace, it will choose the ‘default’ namespace.\nNow, we wait until the images get pulled and deployed. You can watch the pods by running:\n1 kubectl get pods -w After all the pods are deployed, to access Gitea, we need to either open a port or create an ingress. Let’s try the port-forwarding mechanism for now to test the app:\n1 kubectl port-forward service/gitea-http 3000:3000 Now go to http://localhost:3000 and test, you can login as gitea_admin, password: r8sA8CPHD9!bt6d\nTo access Gitea from another pod, CoreDNS provides a default resolving mechanism in the form: service_name.namespace.svc.cluster.local. In our example, the DNS for Gitea is: gitea-http.default.\nDeploy Controller Nginx For testing purposes, port-forwarding may be a good solution, but if we want a more reliable solution and even attach a domain with HTTPS to the Gitea service, we need an ingress.\nTo start with ingress, an ingress controller is needed. We will choose the most popular one: nginx-ingress.\nfollowing this article, choosing helm install, I got the below command to run:\n1 helm install my-release oci://ghcr.io/nginxinc/charts/nginx-ingress --version 1.2.1 If everything works as expected, you should see an ingress-controller service with an IP address from your load-balancer (MetalLB) pool of IP addresses.\nGreat, to expose Gitea, we will change the previous chart file ‘values-gitea.yaml’ values:\n1 2 3 4 5 6 7 8 ingress: enabled: true className: nginx hosts: - host: gitea.homelab.local paths: - path: / pathType: Prefix here we instructed to create an ingress rule:\n- className is needed if you have multiple ingress controllers installed - the host part tell ingress to accept any request with domain or host header : gitea.homelab.local and forward it to gitea instance To redeploy the release with the new configuration, we run:\n1 helm upgrade gitea gitea-charts/gitea --values values-gitea.yaml If we check the ingresses, we can find Gitea ingress has been created. To test it, we will query the IP address of the ingress, supplying a custom host header: gitea.homelab.local.\n1 curl --header 'Host: gitea.homelab.local' ingress_ip_address Deploy bind9 You may notice that accessing Gitea from a browser isn’t possible because the local DNS server doesn’t have knowledge of the domain: homelab.local. The solution is either to modify the /etc/hosts file or create a CT in Proxmox and host a DNS server there.\nI went for the second option, hosting a DNS server because my homelab may require a variety of services in the future, and I want them to be mapped to a domain for all the connected devices in my network.\nFor the DNS server, Pi-hole may be the most popular option for ad-blocking and adding DNS records, but I experienced a few bugs with serving DNS, so I went with the second option: Bind9.\nI read this article\nI created a CT in proxmox and assigned a static ip 192.168.1.114, don’t use dhcp because it may change if CT restarted. So here are my configuration\nmy local ip address: 192.168.1.104, ingress ip address: 192.168.1.148\nfilename: /etc/bind/named.conf.options\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 acl \"trusted\" { 192.168.1.0/24; }; options { directory \"/var/cache/bind\"; // If there is a firewall between you and nameservers you want // to talk to, you may need to fix the firewall to allow multiple // ports to talk. See http://www.kb.cert.org/vuls/id/800113 // If your ISP provided one or more IP addresses for stable // nameservers, you probably want to use them as forwarders. // Uncomment the following block, and insert the addresses replacing // the all-0's placeholder. recursion yes; allow-recursion { trusted; }; listen-on { 192.168.1.114;}; allow-transfer { none; }; // forwarders { // 0.0.0.0; // }; //======================================================================== // If BIND logs error messages about the root key being expired, // you will need to update your keys. See https://www.isc.org/bind-keys //======================================================================== dnssec-validation auto; listen-on-v6 { any; }; }; filename: /etc/bind/named.conf.local\n1 2 3 4 5 6 7 8 zone \"homelab.local\" { type master; file \"/etc/bind/zones/db.homelab.local\"; }; zone \"168.192.in-addr.arpa\" { type primary; file \"/etc/bind/zones/db.192.168\"; # 192.168.0.0/24 subnet }; filename: zones/db.homelab.local\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ; ; BIND data file for local loopback interface ; $TTL 604800 @ IN SOA homelab.local. admin.homelab.local. ( 3 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; ; name servers - NS records IN NS ns1.homelab.local. ; name servers - A records ns1.homelab.local. IN A 192.168.1.114 ; name servers - A records gitea.homelab.local. IN A 192.168.1.148 filename: /etc/bind/zones/db.168.192\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ; ; BIND reverse data file for local loopback interface ; $TTL 604800 @ IN SOA ns1.homelab.local. admin.homelab.local. ( 3 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; name servers - NS records IN NS ns1.homelab.local. ; PTR Records 114.1 IN PTR ns1.homelab.local. ; 192.168.1.114 148.1 IN PTR gitea.homelab.local. ; 192.168.1.148 once the the bind9 configured and it’s working, we need to add the dns server ip address as an additional one, am using NetworkManager:\nAdd TLS Now, if we try to login into to the Gitea registry using the below command:\n1 docker login gitea.homelab.local It will return an error claiming the registry domain needs a TLS certificate. We can work around that by adding the registry domain to /etc/docker/daemon.json, but it would be more useful if we create a TLS certificate and append it to the domain.\nWe will start first by creating the cert. I chose mkcert because my first search led to it 😄.\n1 mkcert gitea.homelab.local It will generate two PEM files: a public key and a private key.\nWe will create a TLS secret and append the two created files from mkcert:\n1 2 3 kubectl create secret tls gitea-secret \\ --key gitea.homelab.local-key.pem \\ --cert gitea.homelab.local.pem Finally, we append the gitea-secret into the ingress by changing the gitea-values.yaml file:\n1 2 3 4 tls: - secretName: gitea-secret hosts: - gitea.homelab.local Now, we can visit gitea.homelab.local and login to gitea registry without issues.\nChange nginx config for pushing the image We deployed Gitea with one main purpose in mind: pushing containers to the registry. However, if we try building a local image and pushing it, you may face an error saying: “413 Request Entity Too Large”!\nThis is because by default Nginx imposes a limit of 1MB for uploading media files. To change that, we add an annotation for ingress to remove the limit:\n1 2 annotations: nginx.org/client-max-body-size: \"0\" then we update the release chart\n1 helm upgrade gitea gitea-charts/gitea --values values-gitea.yaml Now, we can push the image: gitlab.homelab.local/gitea_admin/app:latest\nif you have created another user instead of gitea_admin, you can replace it in the above command.\nAdd Bind9 Server in CoreDNS We have done everything from deploying to adding TLS cert, but if we tried to create a deployment with the deployed image as an example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 apiVersion: apps/v1 kind: Deployment metadata: name: app-deployment labels: app: app spec: selector: matchLabels: app: app template: metadata: labels: app: app spec: containers: - name: app image: gitea.homelab.local/gitea_admin/app:latest ports: - containerPort: 80 after applying the yaml, if you run kubectl describe deployment/app_name you may notice in the events section that it’s stating pulling the image has failed, that’s logical because kubernetes cluster doesn’t know about our custom domain: homelab.local.\nSo to let kubernetes DNS server: CoreDNS, acknowledge our domain we gonna need a litle tweak into the CoreDNS config\nwe run the following command to open the editor with configmap:\n1 kubectl edit configmap -n kube-system coredns and then we add the reference to homelab.local\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 apiVersion: v1 kind: ConfigMap metadata: name: coredns namespace: kube-system data: Corefile: | .:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure fallthrough in-addr.arpa ip6.arpa } prometheus :9153 forward . 172.16.0.1 cache 30 loop reload loadbalance } homalb.local:53 { errors cache 30 forward . 192.168.1.114 } and for the CoreDNS to take effect, we will restart it with :\n1 kubectl rollout restart -n kube-system deployment/coredns Now, to test things out you can redeploy the previous deployed yaml or just run an alpine with nslookup\n1 kubectl run --image=alpine:3.5 -it alpine-shell-1 -- nslookup gitea.homelab.local it should return the ip address of the ingress.\n","wordCount":"1863","inLanguage":"en","image":"//localhost:1313/img/deploy_gitea.jpg","datePublished":"2023-05-20T16:12:38+01:00","dateModified":"2023-05-20T16:12:38+01:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"//localhost:1313/posts/deploy-gitea-k8s/"},"publisher":{"@type":"Organization","name":"chown u+r mind","logo":{"@type":"ImageObject","url":"//localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//localhost:1313/ accesskey=h title="chown u+r mind (Alt + H)"><img src=//localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>chown u+r mind</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=//localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=//localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=//localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Deploying gitea into kubernetes with custom domain</h1><div class=post-meta><span title='2023-05-20 16:12:38 +0100 CET'>May 20, 2023</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1863 words&nbsp;·&nbsp;Me</div></header><figure class=entry-cover><img loading=eager src=//localhost:1313/img/deploy_gitea.jpg alt></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a></li><li><a href=#prerequisite>Prerequisite</a></li><li><a href=#create-pvc-for-nfs-server>Create PVC for NFS Server</a></li><li><a href=#deploy-gitea--postgresql--redis>Deploy Gitea + PostgreSQL + Redis</a></li><li><a href=#deploy-controller-nginx>Deploy Controller Nginx</a></li><li><a href=#deploy-bind9>Deploy bind9</a></li><li><a href=#add-tls>Add TLS</a></li><li><a href=#change-nginx-config-for-pushing-the-image>Change nginx config for pushing the image</a></li><li><a href=#add-bind9-server-in-coredns>Add Bind9 Server in CoreDNS</a></li></ul></nav></div></details></div><div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Hello, lately I have been trying to deploy a custom Docker image into my local Kubernetes cluster. It turned out I needed to host my Docker image on a container registry, either Docker Hub, which is not suitable for my use case, or deploy and use a local registry. During my research, I found Gitea, which I liked as it allows me to deploy all my projects on it and also host the containers.</p><h2 id=prerequisite>Prerequisite<a hidden class=anchor aria-hidden=true href=#prerequisite>#</a></h2><pre><code>* kubernetes cluster
* external server(S3,NFS) for dynamic provisioning
* metallb installed
</code></pre><h2 id=create-pvc-for-nfs-server>Create PVC for NFS Server<a hidden class=anchor aria-hidden=true href=#create-pvc-for-nfs-server>#</a></h2><p>With the help of Proxmox, I created a VM and configured it as an NFS server on 192.168.1.109. To use this server in our Kubernetes cluster, we need to create a StorageClass and then create a PVC that points to that class so pods can use it.</p><p><img loading=lazy src=/img/pvc.png alt=pvc></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --create-namespace <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --namespace nfs-provisioner <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set nfs.server<span class=o>=</span>192.168.1.109 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set nfs.path<span class=o>=</span>/srv/public/nfs
</span></span></code></pre></td></tr></table></div></div><p>Then we create a PVC, linking it to the storageClassName:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolumeClaim</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nfs-test</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>storage.k8s.io/name</span><span class=p>:</span><span class=w> </span><span class=l>nfs</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>storage.k8s.io/part-of</span><span class=p>:</span><span class=w> </span><span class=l>kubernetes-complete-reference</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>ReadWriteMany</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>storageClassName</span><span class=p>:</span><span class=w> </span><span class=l>nfs-client</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>15Gi</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>If we want the deployment to store its volume in NFS, we define volumes with the argument persistentVolumeClaim = nfs-test. Here is an example:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Pod</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>task-pv-pod</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>task-pv-storage</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>nfs-test</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=l>...</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h2 id=deploy-gitea--postgresql--redis>Deploy Gitea + PostgreSQL + Redis<a hidden class=anchor aria-hidden=true href=#deploy-gitea--postgresql--redis>#</a></h2><p>To facilitate deploying resources into Kubernetes, we use Helm. With one command and changing a few values, we can deploy our resources. Before deploying, when I was reading the Gitea chart, I noticed Gitea requires PostgreSQL and Redis to be deployed alongside it to save its configs and states.</p><p>So let&rsquo;s create a file &lsquo;values-gitea.yaml&rsquo; and add the default chart values.</p><p>Then change the following values:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>persistence</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>create</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>nfs-test</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>postgresql-ha</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>postgresql</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>I disabled the deployment of Postgres-HA because I didn&rsquo;t need it for my use case. However, if you&rsquo;re deploying for your organization where multiple users are pushing and pulling, you may keep it enabled.</p><p>Now to deploy the Helm release with the modifications, run:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  helm install gitea gitea-charts/gitea --values values-gitea.yaml
</span></span></code></pre></td></tr></table></div></div><blockquote><p><strong><em>NOTE:</em></strong> You need a cluster with an internet connection to pull the Docker images.</p></blockquote><blockquote><p><strong><em>NOTE:</em></strong> If you don&rsquo;t specify the namespace, it will choose the &lsquo;default&rsquo; namespace.</p></blockquote><p>Now, we wait until the images get pulled and deployed. You can watch the pods by running:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  kubectl get pods -w
</span></span></code></pre></td></tr></table></div></div><p><img loading=lazy src=/img/k9s_screenshoot.png alt="k9s pods"></p><p>After all the pods are deployed, to access Gitea, we need to either open a port or create an ingress. Let&rsquo;s try the port-forwarding mechanism for now to test the app:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl port-forward service/gitea-http 3000:3000
</span></span></code></pre></td></tr></table></div></div><p>Now go to <a href=http://localhost:3000>http://localhost:3000</a> and test, you can login as gitea_admin, password: r8sA8CPHD9!bt6d</p><p>To access Gitea from another pod, CoreDNS provides a default resolving mechanism in the form: service_name.namespace.svc.cluster.local. In our example, the DNS for Gitea is: gitea-http.default.</p><h2 id=deploy-controller-nginx>Deploy Controller Nginx<a hidden class=anchor aria-hidden=true href=#deploy-controller-nginx>#</a></h2><p>For testing purposes, port-forwarding may be a good solution, but if we want a more reliable solution and even attach a domain with HTTPS to the Gitea service, we need an ingress.</p><p>To start with ingress, an ingress controller is needed. We will choose the most popular one: nginx-ingress.</p><p>following this <a href=https://docs.nginx.com/nginx-ingress-controller/installation/installing-nic/installation-with-helm/>article</a>, choosing helm install, I got the below command to run:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>  helm install my-release oci://ghcr.io/nginxinc/charts/nginx-ingress --version 1.2.1
</span></span></code></pre></td></tr></table></div></div><p>If everything works as expected, you should see an ingress-controller service with an IP address from your load-balancer (MetalLB) pool of IP addresses.</p><p><img loading=lazy src=/img/nginx_controller.png alt="nginx-ingress service"></p><p>Great, to expose Gitea, we will change the previous chart file &lsquo;values-gitea.yaml&rsquo; values:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>  </span><span class=nt>ingress</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>className</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>gitea.homelab.local</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>paths</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>pathType</span><span class=p>:</span><span class=w> </span><span class=l>Prefix</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>here we instructed to create an ingress rule:</p><pre><code>- className is needed if you have multiple ingress controllers installed
- the host part tell ingress to accept any request with domain or  host header : gitea.homelab.local and forward it to gitea instance  
</code></pre><p>To redeploy the release with the new configuration, we run:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm upgrade gitea gitea-charts/gitea --values values-gitea.yaml
</span></span></code></pre></td></tr></table></div></div><p>If we check the ingresses, we can find Gitea ingress has been created. To test it, we will query the IP address of the ingress, supplying a custom host header: gitea.homelab.local.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl --header <span class=s1>&#39;Host: gitea.homelab.local&#39;</span> ingress_ip_address
</span></span></code></pre></td></tr></table></div></div><h2 id=deploy-bind9>Deploy bind9<a hidden class=anchor aria-hidden=true href=#deploy-bind9>#</a></h2><p>You may notice that accessing Gitea from a browser isn&rsquo;t possible because the local DNS server doesn&rsquo;t have knowledge of the domain: homelab.local. The solution is either to modify the /etc/hosts file or create a CT in Proxmox and host a DNS server there.</p><p>I went for the second option, hosting a DNS server because my homelab may require a variety of services in the future, and I want them to be mapped to a domain for all the connected devices in my network.</p><p>For the DNS server, Pi-hole may be the most popular option for ad-blocking and adding DNS records, but I experienced a few bugs with serving DNS, so I went with the second option: Bind9.</p><p>I read this <a href=https://www.digitalocean.com/community/tutorials/how-to-configure-bind-as-a-private-network-dns-server-on-ubuntu-20-04#step-2-configuring-the-primary-dns-server>article</a></p><p>I created a CT in proxmox and assigned a static ip 192.168.1.114, don&rsquo;t use dhcp because it may change if CT restarted. So here are my configuration</p><p><strong>my local ip address</strong>: 192.168.1.104, <strong>ingress ip address</strong>: 192.168.1.148</p><p>filename: /etc/bind/named.conf.options</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>acl &#34;trusted&#34; {
</span></span><span class=line><span class=cl>  192.168.1.0/24;
</span></span><span class=line><span class=cl>};
</span></span><span class=line><span class=cl>options {
</span></span><span class=line><span class=cl>  directory &#34;/var/cache/bind&#34;;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  // If there is a firewall between you and nameservers you want
</span></span><span class=line><span class=cl>  // to talk to, you may need to fix the firewall to allow multiple
</span></span><span class=line><span class=cl>  // ports to talk.  See http://www.kb.cert.org/vuls/id/800113
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  // If your ISP provided one or more IP addresses for stable
</span></span><span class=line><span class=cl>  // nameservers, you probably want to use them as forwarders.
</span></span><span class=line><span class=cl>  // Uncomment the following block, and insert the addresses replacing
</span></span><span class=line><span class=cl>  // the all-0&#39;s placeholder.
</span></span><span class=line><span class=cl>  recursion yes;
</span></span><span class=line><span class=cl>  allow-recursion { trusted; };
</span></span><span class=line><span class=cl>  listen-on { 192.168.1.114;};
</span></span><span class=line><span class=cl>  allow-transfer { none; };
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  // forwarders {
</span></span><span class=line><span class=cl>  //      0.0.0.0;
</span></span><span class=line><span class=cl>  // };
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  //========================================================================
</span></span><span class=line><span class=cl>  // If BIND logs error messages about the root key being expired,
</span></span><span class=line><span class=cl>  // you will need to update your keys.  See https://www.isc.org/bind-keys
</span></span><span class=line><span class=cl>  //========================================================================
</span></span><span class=line><span class=cl>  dnssec-validation auto;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  listen-on-v6 { any; };
</span></span><span class=line><span class=cl>};
</span></span></code></pre></td></tr></table></div></div><p>filename: /etc/bind/named.conf.local</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>zone &#34;homelab.local&#34; {
</span></span><span class=line><span class=cl>    type master;
</span></span><span class=line><span class=cl>    file &#34;/etc/bind/zones/db.homelab.local&#34;;
</span></span><span class=line><span class=cl>};
</span></span><span class=line><span class=cl>zone &#34;168.192.in-addr.arpa&#34; {
</span></span><span class=line><span class=cl>    type primary;
</span></span><span class=line><span class=cl>    file &#34;/etc/bind/zones/db.192.168&#34;;  # 192.168.0.0/24 subnet
</span></span><span class=line><span class=cl>};
</span></span></code></pre></td></tr></table></div></div><p>filename: zones/db.homelab.local</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>
</span></span><span class=line><span class=cl>;
</span></span><span class=line><span class=cl>; BIND data file for local loopback interface
</span></span><span class=line><span class=cl>;
</span></span><span class=line><span class=cl>$TTL    604800
</span></span><span class=line><span class=cl>@       IN      SOA     homelab.local. admin.homelab.local. (
</span></span><span class=line><span class=cl>                              3         ; Serial
</span></span><span class=line><span class=cl>                         604800         ; Refresh
</span></span><span class=line><span class=cl>                          86400         ; Retry
</span></span><span class=line><span class=cl>                        2419200         ; Expire
</span></span><span class=line><span class=cl>                         604800 )       ; Negative Cache TTL
</span></span><span class=line><span class=cl>;
</span></span><span class=line><span class=cl>; name servers - NS records
</span></span><span class=line><span class=cl>    IN      NS      ns1.homelab.local.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>; name servers - A records
</span></span><span class=line><span class=cl>ns1.homelab.local.            IN      A       192.168.1.114
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>; name servers - A records
</span></span><span class=line><span class=cl>gitea.homelab.local.          IN      A       192.168.1.148
</span></span></code></pre></td></tr></table></div></div><p>filename: /etc/bind/zones/db.168.192</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>;
</span></span><span class=line><span class=cl>; BIND reverse data file for local loopback interface
</span></span><span class=line><span class=cl>;
</span></span><span class=line><span class=cl>$TTL    604800
</span></span><span class=line><span class=cl>@       IN      SOA     ns1.homelab.local. admin.homelab.local. (
</span></span><span class=line><span class=cl>                              3         ; Serial
</span></span><span class=line><span class=cl>                         604800         ; Refresh
</span></span><span class=line><span class=cl>                          86400         ; Retry
</span></span><span class=line><span class=cl>                        2419200         ; Expire
</span></span><span class=line><span class=cl>                         604800 )       ; Negative Cache TTL
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>; name servers - NS records
</span></span><span class=line><span class=cl>      IN      NS      ns1.homelab.local.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>; PTR Records
</span></span><span class=line><span class=cl>114.1   IN      PTR     ns1.homelab.local.    ; 192.168.1.114
</span></span><span class=line><span class=cl>148.1   IN      PTR     gitea.homelab.local.  ; 192.168.1.148
</span></span></code></pre></td></tr></table></div></div><p>once the the bind9 configured and it&rsquo;s working, we need to add the dns server ip address as an additional one, am using NetworkManager:</p><p><img loading=lazy src=/img/network_manager_dns.png alt=network_manager></p><h2 id=add-tls>Add TLS<a hidden class=anchor aria-hidden=true href=#add-tls>#</a></h2><p>Now, if we try to login into to the Gitea registry using the below command:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker login gitea.homelab.local
</span></span></code></pre></td></tr></table></div></div><p>It will return an error claiming the registry domain needs a TLS certificate. We can work around that by adding the registry domain to /etc/docker/daemon.json, but it would be more useful if we create a TLS certificate and append it to the domain.</p><p>We will start first by creating the cert. I chose mkcert because my first search led to it 😄.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>mkcert gitea.homelab.local
</span></span></code></pre></td></tr></table></div></div><p>It will generate two PEM files: a public key and a private key.</p><p>We will create a TLS secret and append the two created files from mkcert:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl create secret tls gitea-secret <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --key gitea.homelab.local-key.pem <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>    --cert gitea.homelab.local.pem
</span></span></code></pre></td></tr></table></div></div><p>Finally, we append the gitea-secret into the ingress by changing the gitea-values.yaml file:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>tls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>secretName</span><span class=p>:</span><span class=w> </span><span class=l>gitea-secret</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span>- <span class=l>gitea.homelab.local</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>Now, we can visit gitea.homelab.local and login to gitea registry without issues.</p><p><img loading=lazy src=/img/docker_login.png alt=docker-login></p><h2 id=change-nginx-config-for-pushing-the-image>Change nginx config for pushing the image<a hidden class=anchor aria-hidden=true href=#change-nginx-config-for-pushing-the-image>#</a></h2><p>We deployed Gitea with one main purpose in mind: pushing containers to the registry. However, if we try building a local image and pushing it, you may face an error saying: &ldquo;413 Request Entity Too Large&rdquo;!</p><p><img loading=lazy src=/img/docker_push_413.png alt=413_push_image></p><p>This is because by default Nginx imposes a limit of 1MB for uploading media files. To change that, we add an annotation for ingress to remove the limit:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>nginx.org/client-max-body-size</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0&#34;</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>then we update the release chart</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>helm upgrade gitea gitea-charts/gitea --values values-gitea.yaml
</span></span></code></pre></td></tr></table></div></div><p>Now, we can push the image: gitlab.homelab.local/gitea_admin/app:latest</p><p><img loading=lazy src=/img/pushed_image.png alt=pushed_image></p><p>if you have created another user instead of gitea_admin, you can replace it in the above command.</p><h2 id=add-bind9-server-in-coredns>Add Bind9 Server in CoreDNS<a hidden class=anchor aria-hidden=true href=#add-bind9-server-in-coredns>#</a></h2><p>We have done everything from deploying to adding TLS cert, but if we tried to create a deployment with the deployed image as an example</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>app-deployment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>gitea.homelab.local/gitea_admin/app:latest</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>after applying the yaml, if you run kubectl describe deployment/app_name
you may notice in the events section that it&rsquo;s stating pulling the image has failed, that&rsquo;s logical because kubernetes cluster doesn&rsquo;t know about our custom domain: <strong>homelab.local</strong>.</p><p>So to let kubernetes DNS server: CoreDNS, acknowledge our domain we gonna need a litle tweak into the CoreDNS config</p><p>we run the following command to open the editor with configmap:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl edit configmap -n kube-system coredns
</span></span></code></pre></td></tr></table></div></div><p>and then we add the reference to homelab.local</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ConfigMap</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>coredns</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>kube-system</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>Corefile</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>    .:53 {
</span></span></span><span class=line><span class=cl><span class=sd>        errors
</span></span></span><span class=line><span class=cl><span class=sd>        health
</span></span></span><span class=line><span class=cl><span class=sd>        kubernetes cluster.local in-addr.arpa ip6.arpa {
</span></span></span><span class=line><span class=cl><span class=sd>           pods insecure
</span></span></span><span class=line><span class=cl><span class=sd>           fallthrough in-addr.arpa ip6.arpa
</span></span></span><span class=line><span class=cl><span class=sd>        }
</span></span></span><span class=line><span class=cl><span class=sd>        prometheus :9153
</span></span></span><span class=line><span class=cl><span class=sd>        forward . 172.16.0.1
</span></span></span><span class=line><span class=cl><span class=sd>        cache 30
</span></span></span><span class=line><span class=cl><span class=sd>        loop
</span></span></span><span class=line><span class=cl><span class=sd>        reload
</span></span></span><span class=line><span class=cl><span class=sd>        loadbalance
</span></span></span><span class=line><span class=cl><span class=sd>    }
</span></span></span><span class=line><span class=cl><span class=sd>    homalb.local:53 {
</span></span></span><span class=line><span class=cl><span class=sd>        errors
</span></span></span><span class=line><span class=cl><span class=sd>        cache 30
</span></span></span><span class=line><span class=cl><span class=sd>        forward . 192.168.1.114
</span></span></span><span class=line><span class=cl><span class=sd>    }  </span><span class=w>    
</span></span></span></code></pre></td></tr></table></div></div><p>and for the CoreDNS to take effect, we will restart it with :</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl rollout restart -n kube-system deployment/coredns
</span></span></code></pre></td></tr></table></div></div><p>Now, to test things out you can redeploy the previous deployed yaml or just run an alpine with nslookup</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>kubectl run --image<span class=o>=</span>alpine:3.5 -it alpine-shell-1 -- nslookup gitea.homelab.local
</span></span></code></pre></td></tr></table></div></div><p>it should return the ip address of the ingress.</p></div><footer class=post-footer><ul class=post-tags><li><a href=//localhost:1313/tags/kubernetes/>Kubernetes</a></li><li><a href=//localhost:1313/tags/giea/>Giea</a></li><li><a href=//localhost:1313/tags/dns/>Dns</a></li><li><a href=//localhost:1313/tags/helm/>Helm</a></li><li><a href=//localhost:1313/tags/proxmox/>Proxmox</a></li><li><a href=//localhost:1313/tags/bind9/>Bind9</a></li></ul><nav class=paginav><a class=prev href=//localhost:1313/posts/etcd_went_down/><span class=title>« Prev</span><br><span>Oops...Etcd went down</span>
</a><a class=next href=//localhost:1313/posts/hide-your-secrets/><span class=title>Next »</span><br><span>GCP -> AWS Migration: Hide Your Secrets</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on x" href="https://x.com/intent/tweet/?text=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f&amp;hashtags=Kubernetes%2cgiea%2cdns%2chelm%2cproxmox%2cbind9"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f&amp;title=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain&amp;summary=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain&amp;source=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on reddit" href="https://reddit.com/submit?url=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f&title=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on facebook" href="https://facebook.com/sharer/sharer.php?u=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on whatsapp" href="https://api.whatsapp.com/send?text=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain%20-%20%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on telegram" href="https://telegram.me/share/url?text=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deploying gitea into kubernetes with custom domain on ycombinator" href="https://news.ycombinator.com/submitlink?t=Deploying%20gitea%20into%20kubernetes%20with%20custom%20domain&u=%2f%2flocalhost%3a1313%2fposts%2fdeploy-gitea-k8s%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=//localhost:1313/>chown u+r mind</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><style>.disqus_thread{display:flex;width:50%;margin:auto;height:5%}</style><div id=disqus_thread class=disqus_thread></div><script type=text/javascript>(function(){var t,e=document.createElement("script");e.type="text/javascript",e.async=!0,t="",e.src="//"+t+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript><a href=https://disqus.com/ class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></body></html>