<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Deployment Preview with AWS CloudFront | chown u+r mind</title>
<meta name=keywords content="AWS,CloudFront,CI/CD pipeline,FrontEnd"><meta name=description content="Introduction Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.
With a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.
In this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3."><meta name=author content="Me"><link rel=canonical href=//localhost:1313/posts/deployment-preview-with-aws-cloudfront/><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=//localhost:1313/posts/deployment-preview-with-aws-cloudfront/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Deployment Preview with AWS CloudFront"><meta property="og:description" content="Introduction Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.
With a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.
In this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3."><meta property="og:type" content="article"><meta property="og:url" content="//localhost:1313/posts/deployment-preview-with-aws-cloudfront/"><meta property="og:image" content="//localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-10T11:39:04+01:00"><meta property="article:modified_time" content="2023-01-10T11:39:04+01:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="//localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Deployment Preview with AWS CloudFront"><meta name=twitter:description content="Introduction Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.
With a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.
In this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"//localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Deployment Preview with AWS CloudFront","item":"//localhost:1313/posts/deployment-preview-with-aws-cloudfront/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deployment Preview with AWS CloudFront","name":"Deployment Preview with AWS CloudFront","description":"Introduction Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.\nWith a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.\nIn this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3.","keywords":["AWS","CloudFront","CI/CD pipeline","FrontEnd"],"articleBody":"Introduction Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.\nWith a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.\nIn this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3.\nIn the end, this tutorial will expand your knowledge of AWS Services and help you speed up your development and deployment process.\nBefore starting, here is a playlist to enjoy reading with\nTo accomplish this tutorial, you‚Äôll need:\nan AWS account with administrative permissions an AWS CLI with a minimum version of 2.4.6 a runnable React app hosted on GitHub basic knowledge of YAML file structure clone this simple react app Creating CI Pipeline To build a resilient system, you need to add tests on your code then run them locally and on every push to version control. In this step, you will build a CI pipeline that triggers every pull request creation or update on your GitHub repository, the pipeline will run the desired tests and return a badge containing the status of the tests to your GitHub.\nCreate the file pull-request.yml in your text editor:\nnano pull-request.yml Add the following CloudFormation code to the file, which builds a CodeBuildProject that defines a CI pipeline with GitHub integration:\nResources: CodeBuildProject: Type: AWS::CodeBuild::Project Properties: Name: FrontBuildOnPull ServiceRole: !GetAtt BuildProjectRole.Arn LogsConfig: CloudWatchLogs: GroupName: !Ref BuildLogGroup Status: ENABLED StreamName: front_pull_request EncryptionKey: \"alias/aws/s3\" Artifacts: Type: S3 Location: !Ref ArtifactBucket Name: FrontPullRequest OverrideArtifactName: true EncryptionDisabled: true Environment: Type: LINUX_CONTAINER ComputeType: BUILD_GENERAL1_MEDIUM Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0 Source: Type: GITHUB Location: \"https://github.com/projectX/repoY\" ReportBuildStatus: true Triggers: BuildType: BUILD Webhook: true FilterGroups: - - Type: EVENT Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED Visibility: PUBLIC_READ ResourceAccessRole: !Ref PublicReadRole I will briefly explain the CloudFormation template structure, so you can get a general understanding of CloudFormation files that guides you through the next steps.\nThe majority of CloudFormation template files will contain Parameters(Optional) and Resources(Required), Outputs(Optional), each block on the Resources is a Service, and every Service contains Type and Properties. The type is referred to as AWS Service or a Custom Function and each Type has a different set of properties.\nLet‚Äôs analyze the above Code to understand better. Here we have a Resources block that contains three Services. The CodeBuildProject refers to AWS::CodeBuild::Project which is an AWS Service for CodeBuild. The CodeBuild has a set of properties, you can find them here properties, I will explain each property functionality and why we‚Äôre adding it.\nGive CodeBuild the required permissions For CodeBuild to work we need to assign the ServiceRole an IAM Role to give CodeBuild the right to access other AWS services like secrets, S3, and logs.\n... ServiceRole: !GetAtt BuildProjectRole.Arn ... ... BuildProjectRole is a role that assumes the principal ‚Äúcodebuild.amazonaws.com‚Äù the permission to use a set of services on our behalf of us, more reading about AWS::IAM::ROLE\nAfter, we need to ask ourselves what services CodeBuild must have access to and what we want to access on each of the services:\nCodebuild needs to create and update the test reports. CodeBuild needs to store the CI process logs inside a logs group. CodeBuild needs to access the secrets manager to get some secret credentials ex: CYPRESS_KEY. - CodeBuild needs to get and store React build folder on S3. Now after we defined our requirements, we create BuildProjectPolicy which is an AWS::IAM::Policy for BuildProjectRole that contains the list of statements, and each statement is composed of a set of actions.\nBuildProjectRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: '2012-10-17' Statement: - Effect: Allow Principal: Service: - codebuild.amazonaws.com Action: - sts:AssumeRole BuildProjectPolicy: Type: AWS::IAM::Policy DependsOn: BuildProjectRole Properties: PolicyName: !Sub ${AWS::StackName}-CodeBuildPolicy PolicyDocument: Version: '2012-10-17' Statement: - Effect: Allow Action: - codebuild:CreateReportGroup - codebuild:CreateReport - codebuild:UpdateReport - codebuild:BatchPutTestCases - codebuild:BatchPutCodeCoverages # Create and update test report Resource: \"*\" - Effect: Allow Action: - s3:PutObject - s3:GetObject - s3:GetObjectVersion # Get and store React build folder on S3 Resource: \"*\" - Effect: Allow Action: - logs:CreateLogGroup - logs:CreateLogStream - logs:PutLogEvents # Store the CI process logs inside a logs group Resource: arn:aws:logs:*:*:* - Effect: Allow Action: - secretsmanager:* # Get secret creedentials ex: CYPRESS_KEY Resource: \"*\" Roles: - !Ref BuildProjectRole Access and Store CodeBuild Logs Logs are an important key of DevOps because it adds the visibility aspect to the infrastructure, so gather logs as much as you can. In our case, to enable logs for CodeBuild project we create LogsConfig property.\n... ... LogsConfig: CloudWatchLogs: GroupName: !Ref BuildLogGroup Status: ENABLED StreamName: front_pull_request ... ... Now, we need to create a LogGroup to which CodeBuild pushes logs to\nBuildLogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: frontend_build_on_pull RetentionInDays: 7 RetentionInDays is the period after which the logs expire.\nAccess and Store React Builds After successfully building and testing the project, we should store the build folder on S3 so we can access it again when the developer wants to see his changes. So we create an Artifacts property that stores build on an S3 bucket called ‚ÄúArtifactBucket‚Äù\n... ... Artifacts: Type: S3 Location: !Ref ArtifactBucket Name: FrontPullRequest OverrideArtifactName: true EncryptionDisabled: true ... ... OverrideArtifactName we use to customize the path where we store the builds.\nEncryptionDisabled we disabled it because we don‚Äôt need custom encryption in our case, we will be using the default one instead.\nArtifactBucket: Type: 'AWS::S3::Bucket' DeletionPolicy: Delete Properties: BucketName: \"some-random-unique-bucket-name\" BucketEncryption: ServerSideEncryptionConfiguration: - ServerSideEncryptionByDefault: SSEAlgorithm: AES256 PublicAccessBlockConfiguration: BlockPublicAcls: true BlockPublicPolicy: true IgnorePublicAcls: true RestrictPublicBuckets: true ArtifactBucket is a resource block that refers to AWS::S3::Bucket, also we should add some properties to restrict public access to build folders and define how the data must be encrypted when it gets stored.\nName: you need to change to your unique bucket name, the name must be unique across all AWS buckets.\nBucketEncryption we use Amazon S3 server-side encryption which uses 256-bit Advanced Encryption Standard(AES256).\nPublicAccessBlockConfiguration this property blocks all public access to the public and ignores any policy that allows public visibility of the bucket.\nCodeBuild CI Environment For the CI to work, you must provide information about the CI environment. A build environment represents a combination of the operating system, programming language runtime, and tools that CodeBuild uses to run a build.\n... ... Environment: Type: LINUX_CONTAINER ComputeType: BUILD_GENERAL1_MEDIUM Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0 ... Type this is the OS type, which is Linux for our case.\nComputeType: this provides the CodeBuild with information about the computing resources it‚Äôs allowed to use (7 GB Memory,4vCPU,128GB Disk ).\nImage: A docker image to use during the build which provides the environment with a set of tools and runtimes, here is the documentation for better details\nCodeBuild Trigger and Repo Linking To fire up the build process whenever a pull request is created or updated, you need to add two properties: Source, Triggers\n... ... Source: Type: GITHUB Location: \"https://github.com/projectX/repoY\" ReportBuildStatus: true Triggers: BuildType: BUILD Webhook: true FilterGroups: - - Type: EVENT Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED ... ... Source defines the type of version control and the location, you need to change the Location property to your desired repository, on the other side to report the build status back to version control(Github) you turn ReportBuildStatus to true. Triggers specify webhooks that trigger The AWS CodeBuild build.\nTo allow Codebuild access to your repository, you need to create a personal access token and pass it to CodeBuild so it can access your repo on your behalf, This can be done in two steps:\n1- Generate a personal token from your GitHub account:\nVisit the Personal access tokens Github page, then select ‚ÄúFull control of private repositories‚Äù and ‚ÄúFull control of repository hooks‚Äù and click Generate token.\n2- Pass down the generated token to AWS Codebuild credentials: Run the following command to generate an import-source-credentials.json file on your local :\naws codebuild import-source-credentials --generate-cli-skeleton After, we need to modify import-source-credentials.json and fill it with your credentials:\nauth_type: PERSONAL_ACCESS_TOKEN\nserverType: GITHUB\nusername: your GitHub username\ntoken: the generated token from the previous step.\naws codebuild import-source-credentials ‚Äìcli-input-json file://import-source-credentials.json\nTo test that your command runs successfully, run the following command to list your CodeBuild credentials:\naws codebuild list-source-credentials Now when CodeBuild starts running it will search in your source code for a file named buildspec.yml, by definition :\nA buildspec is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build.\nHere is an example of buildspec.yml from our demo app :\nversion: 0.2 phases: install: commands: - npm install pre_build: on-failure: ABORT commands: - echo \"run some pre-check\" #- npm run format:check #- npm run lint:check build: on-failure: ABORT commands: - echo \"run tests\" # - npm run-script start \u0026 npx wait-on http://localhost:3000 # - npx cypress run --record --key ${CYPRESS_KEY} post_build: commands: - | npm run build artifacts: # include all files required to run application # we include only the static build files files: - '**/*' name: $CODEBUILD_WEBHOOK_TRIGGER base-directory: 'dist' Our CI contains different phases (install, pre_build ‚Ä¶etc), finally, post_build will run when all the previous steps exited successfully.\npost_build will create a dist folder and then CodeBuild will upload the dist folder to S3 under CODEBUILD_WEBHOOK_TRIGGER path that will be /pr/{pr_number}.\nFor example, if a pull request gets created with the number 1, then after CI builds successfully the build folder will get stored on ArtifactBucket under path /pr/1/.\nCI logs Public Visibility To Users The following property gives developers access to see build logs without having an AWS account :\n... ... Visibility: PUBLIC_READ ResourceAccessRole: !Ref PublicReadRole ... then the PublicReadRole must allow access to logs and S3\nPublicReadRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Statement: - Action: ['sts:AssumeRole'] Effect: Allow Principal: Service: [codebuild.amazonaws.com] Version: '2012-10-17' Path: / PublicReadPolicy: Type: 'AWS::IAM::Policy' Properties: PolicyName: PublicBuildPolicy PolicyDocument: Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"logs:GetLogEvents\" Resource: - !Sub \"arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${BuildLogGroup}:*\" - Effect: Allow Action: - \"s3:GetObject\" - \"s3:GetObjectVersion\" Resource: - Fn::Sub: - \"${ArtifcatArn}/*\" - {ArtifcatArn: !GetAtt ArtifactBucket.Arn} Roles: - !Ref PublicReadRole Sum It Up After you understand the full picture of CodeBuild Service and its dependency, you can edit pull-request.yml:\nnano pull-request.yml replace its content with the following code\nResources: CodeBuildProject: Type: AWS::CodeBuild::Project Properties: Name: FrontBuildOnPull ServiceRole: !GetAtt BuildProjectRole.Arn LogsConfig: CloudWatchLogs: GroupName: !Ref BuildLogGroup Status: ENABLED StreamName: front_pull_request EncryptionKey: \"alias/aws/s3\" Artifacts: Type: S3 Location: !Ref ArtifactBucket Name: FrontPullRequest OverrideArtifactName: true EncryptionDisabled: true Environment: Type: LINUX_CONTAINER ComputeType: BUILD_GENERAL1_MEDIUM Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0 Source: Type: GITHUB Location: \"https://github.com/projectX/repoY\" ReportBuildStatus: true Triggers: BuildType: BUILD Webhook: true FilterGroups: - - Type: EVENT Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED Visibility: PUBLIC_READ ResourceAccessRole: !Ref PublicReadRole BuildProjectRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: '2012-10-17' Statement: - Effect: Allow Principal: Service: - codebuild.amazonaws.com Action: - sts:AssumeRole BuildProjectPolicy: Type: AWS::IAM::Policy DependsOn: BuildProjectRole Properties: PolicyName: !Sub ${AWS::StackName}-CodeBuildPolicy PolicyDocument: Version: '2012-10-17' Statement: - Effect: Allow Action: - codebuild:CreateReportGroup - codebuild:CreateReport - codebuild:UpdateReport - codebuild:BatchPutTestCases - codebuild:BatchPutCodeCoverages # Create and update test report Resource: \"*\" - Effect: Allow Action: - s3:PutObject - s3:GetObject - s3:GetObjectVersion # Get and store React build folder on S3 Resource: \"*\" - Effect: Allow Action: - logs:CreateLogGroup - logs:CreateLogStream - logs:PutLogEvents # Store the CI process logs inside a logs group Resource: arn:aws:logs:*:*:* - Effect: Allow Action: - secretsmanager:* # Get secret creedentials ex: CYPRESS_KEY Resource: \"*\" Roles: - !Ref BuildProjectRole BuildLogGroup: Type: AWS::Logs::LogGroup Properties: LogGroupName: frontend_build_on_pull RetentionInDays: 7 ArtifactBucket: Type: 'AWS::S3::Bucket' DeletionPolicy: Delete Properties: BucketName: \"some-random-unique-bucket-name\" BucketEncryption: ServerSideEncryptionConfiguration: - ServerSideEncryptionByDefault: SSEAlgorithm: AES256 PublicAccessBlockConfiguration: BlockPublicAcls: true BlockPublicPolicy: true IgnorePublicAcls: true RestrictPublicBuckets: true PublicReadRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Statement: - Action: ['sts:AssumeRole'] Effect: Allow Principal: Service: [codebuild.amazonaws.com] Version: '2012-10-17' Path: / PublicReadPolicy: Type: 'AWS::IAM::Policy' Properties: PolicyName: PublicBuildPolicy PolicyDocument: Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"logs:GetLogEvents\" Resource: - !Sub \"arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${BuildLogGroup}:*\" - Effect: Allow Action: - \"s3:GetObject\" - \"s3:GetObjectVersion\" Resource: - Fn::Sub: - \"${ArtifcatArn}/*\" - {ArtifcatArn: !GetAtt ArtifactBucket.Arn} Roles: - !Ref PublicReadRole To test our code, move into the pull-request.yml file path and run\naws cloudformation create-stack --stack-name pull-request-preview-stack --template-body file://pull-request.yml --capabilities CAPABILITY_NAMED_IAM Now visit Cloudformation Console and you should see a stack with the name pull-request-preview-stack and its status CREATE_IN_PROGRESS or CREATE_COMPLETE\nServing Content With CloudFront CloudFront is a content delivery network(CDN), CDN can speed up the serving of your static content by caching in the edges that are near you, it is less expensive and it allows you to add a TLS certificate(HTTP) and domain to your static content.\nOn the other side, we don‚Äôt need all of these things but what we want from CloudFront is Lambda@Edge which will allow us to redirect requests by the header to right S3 bucket folder. To explain more, let‚Äôs suppose we made 2 pull-request by numbers 121,122, after 2 of them are tested and built successfully, they will get stored in a folder named pr on the Artifact Bucket with the following structure:\npr/\n121/\nassets index.html ‚Ä¶ ‚Ä¶ 122/\nassets index.html ‚Ä¶ ‚Ä¶ Now when Lambda@Edge comes to play, every request that comes to the CloudFront host(which is a random subdomain under CloudFront xxxxx.cloudfront.net) with a pull-request header and value 122 will be redirected to the folder ‚Äú122‚Äù to serve ‚Äú122‚Äù pull request contents.\nIn this section, you will learn how to serve S3 content from a CDN and customize users requests by different criteria like (header,query-params‚Ä¶etc) and also build a trigger whenever a build runs successfully, it clears the cache of a specific pull request on the CDN for the new contents.\nCreating CloudFront Let‚Äôs edit pull-request.yml\nnano pull-request.yml and add a CloudFront Distribution Service that will primarily serve index.html from ArtifactBucket\nDistribution: Type: AWS::CloudFront::Distribution Properties: DistributionConfig: Origins: - DomainName: !Sub ${ArtifactBucket}.s3.${AWS::Region}.amazonaws.com Id: S3Origin S3OriginConfig: OriginAccessIdentity: !Sub origin-access-identity/cloudfront/${OriginAccessIdentity} Enabled: true DefaultRootObject: index.html Logging: Bucket: !Sub ${DistributionBucket}.s3.${AWS::Region}.amazonaws.com DefaultCacheBehavior: TargetOriginId: S3Origin CachePolicyId: !Ref DistributionCachingPolicy ViewerProtocolPolicy: https-only PriceClass: PriceClass_100 Cloudfront has 4 major properties that we will explain briefly\nOrigins: This property refers to where CloudFront retrieves the content, we will be adding only Artifact Bucket, also there is a sub-property OriginAccessIdentity that restricts access to ArtifactBucket bucket only from CloudFront.\nDefaultRootObject: The default file that CloudFront will render from the bucket\nPriceClass: To how many regions should our content get cached? we choose PriceClass_100 that‚Äôs the minimum value because we don‚Äôt care about that.\nLogging: We should collect access logs, So we store them in a bucket ‚ÄúDistributionBucket‚Äù\nDefaultCacheBehavior is a required property so we will add it, but we don‚Äôt need any caching behavior from CloudFront to test the pull requests. DefaultCacheBehavior contains 3 required attributes:\nTargetOriginId points to one of our Origins which is S3Origin the only origin we have.\nViewerProtocolPolicy controls whether the user is redirected to HTTPS or uses HTTP or both, we chose https-only.\nCachePolicyId , is an important property because we need to allow CloudFront to pass certain headers to Lambda@Edge and the available managed cache policies don‚Äôt allow that, so creating a custom cache policy will help. here is the code for the custom cache policy that allows passing the pull-request header to Lambda@Edge.\nDistributionCachingPolicy: Type: AWS::CloudFront::CachePolicy Properties: CachePolicyConfig: Comment: ‚ÄúAllow pass of header and query params to cloudfront‚Äù DefaultTTL: 86400 MaxTTL: 31536000 MinTTL: 80400 Name: CacheForHeaderAndQuery ParametersInCacheKeyAndForwardedToOrigin: CookiesConfig: CookieBehavior: none EnableAcceptEncodingGzip: false HeadersConfig: HeaderBehavior: whitelist Headers: - pull-request QueryStringsConfig: QueryStringBehavior: all\nNow the problem we‚Äôre facing is that our pull requests content is stored under the PR folder so we cannot serve them as Cloudfront doesn‚Äôt allow dynamic selection of contents. So the solution is rerouting the user request before it reaches the S3 bucket and choosing the right path depending on the custom header(pull-request) he passes on the request.\nChoose The Right Path with Lambda@Edge To add Lambda@Edge to CloudFront we will modify DefaultCacheBehavior to look like this:\nDefaultCacheBehavior: TargetOriginId: S3Origin ViewerProtocolPolicy: redirect-to-https CachePolicyId: !Ref DistributionCachingPolicy LambdaFunctionAssociations: - EventType: 'origin-request' LambdaFunctionARN: !Ref VersionedLambdaFunction Let‚Äôs create the lambda function, the programming language will be python :\nLambdaFunction: Type: 'AWS::Lambda::Function' Properties: FunctionName: \"cloudfront_lambda\" Code: ZipFile: !Sub | import re import boto3 def handler(event, context): client = boto3.client(\"s3\") bucket = \"front-end-preview-bucket\" response = client.list_objects_v2(Bucket=bucket,Prefix=\"pr/\",Delimiter=\"/\") prs = [p['Prefix'].split('/')[1] for p in response['CommonPrefixes']] request = event['Records'][0]['cf']['request'] print(request) headers = request['headers'] pr = headers.get('pull-request',None) if pr is None: print(f\"{pr} not found\") response = { 'status': '404', 'statusDescription': 'No Found', } return response pr = pr[0]['value'] if not pr.isdigit() or not (pr in prs): print(f\"{pr} not good\") response = { 'status': '404', 'statusDescription': 'No Found', } return response pr = int(pr) request['uri'] = f\"/pr/{pr}{request['uri']}\" print(request) return request Handler: 'index.handler' MemorySize: 128 Role: !GetAtt 'LambdaRole.Arn' Runtime: 'python3.9' Timeout: 5 LambdaRole: Type: 'AWS::IAM::Role' Properties: AssumeRolePolicyDocument: Version: '2012-10-17' Statement: - Effect: Allow Principal: Service: - 'lambda.amazonaws.com' - 'edgelambda.amazonaws.com' Action: 'sts:AssumeRole' Policies: - PolicyName: FetchContentFromBucket PolicyDocument: Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"s3:GetObject\" - \"s3:ListBucket\" - \"s3:GetObjectVersion\" Resource: - Fn::Sub: - \"${ArtifcatArn}/*\" - {ArtifcatArn: !GetAtt ArtifactBucket.Arn} ManagedPolicyArns: - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole' - \"arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole\" To summarize what function do, we fetch all current pull requests that are stored on the bucket and whenever a user makes a request, we check the header(pull-request) value and see if it‚Äôs available, if yes we rewrite the request URI to ‚Äú/pr/{pr}{request[‚Äòuri‚Äô]}‚Äù, if no we return 404 response.\nAlso, we assign Lambda different policies, some are managed policies like :\nAWSLambdaBasicExecutionRole AWSLambdaVPCAccessExecutionRole and others are custom like FetchContentFromBucket to query React build folder from ArtifactBucket.\nA Little Demo After understanding what each service does, we update our pull-request.yml file with the above code. then we update cloud formation with the following command:\naws cloudformation update-stack --stack-name pull-request-preview-stack --template-body file://pull-request.yml --capabilities CAPABILITY_NAMED_IAM Now visit Cloudformation Console and you should see a stack with the name pull-request-preview-stack and its status UPDATE_IN_PROGRESS or UPDATE_COMPLETE.\nTo get the CloudFront endpoint Click on pull-request-preview-stack on Cloudformation Console and Click Outputs\nWhat‚Äôs missing now, is creating a pull request in our repository. first, we need a new branch\ngit switch -c feature/test_preview then let‚Äôs make some changes and finally add, commit, push\ngit add . git commit -m \"it's getting darker :black:\" git push --set-upstream origin feature/test_preview Now let‚Äôs wait until the tests pass successfully üëÄ\nIf you visit the CloudFront Endpoint you will get a 404 page, this happens because you didn‚Äôt pass a pull-request number as a header. So to achieve this we need to install a chrome extension ‚Äúmobheader‚Äù\nyou replace 271 with your pull request number that you find on the Github pull request page\nRefresh now, Taddaaaa üéä\nNow, Let‚Äôs suppose that you made a pull request and requested one of your teammates to make a review for you and he reclaimed something buggy is happening, so you went to investigate the issue and solved it and now you‚Äôre pushing the updates. After your CI builds and tests successfully, you visit the CloudFront URL and you find the bug still exists, why ?!.\nWell it‚Äôs because CloudFront caches the build folder on its servers and you need to invalidate the cache from the servers then CloudFront will request the files again from S3\nSo the approach will be creating a Lambda Function that gets triggered whenever the builds run successfully, The function takes CloudFront DistributionId as an environment variable and make an invalidation request to /pr/{pr_number} subfolder\nEventCloudFrontLambda: Type: 'AWS::Events::Rule' Properties: Description: Invalidate Cloudfront after a successful build State: ENABLED EventPattern: source: - aws.codebuild detail-type: - CodeBuild Build State Change detail: build-status: - SUCCEEDED project-name: - !Ref CodeBuildProject Targets: - Arn: !GetAtt InvalidateCloudFront.Arn Id: \"TargetFunctionV1\" InvalidateCloudFront: Type: 'AWS::Lambda::Function' Properties: FunctionName: \"invalidate_cloudfront_from_codebuild_lambda\" Environment: Variables: DistributionId: !GetAtt Distribution.Id Code: ZipFile: !Sub | import boto3 import uuid import os def handler(event, context): print(event) artifict = event['detail']['additional-information']['artifact']['location'] pr = artifict.split(\"/\")[2] distribution_id = os.getenv(\"DistributionId\") print(distribution_id) client = boto3.client(\"cloudfront\") response = client.create_invalidation( DistributionId=distribution_id, InvalidationBatch={ 'Paths': { 'Quantity': 1, 'Items': [ f'/pr/{pr}/*', ] }, 'CallerReference': str(uuid.uuid4()) } ) return {\"status\":200} Handler: 'index.handler' MemorySize: 128 Role: !GetAtt 'LambdaRole.Arn' Runtime: 'python3.9' Timeout: 15 InvalidateCloudFrontLogs: Type: AWS::Logs::LogGroup DependsOn: InvalidateCloudFront Properties: LogGroupName: !Sub \"/aws/lambda/${InvalidateCloudFront}\" RetentionInDays: 7 PermissionForEventsToInvokeLambda: Type: AWS::Lambda::Permission Properties: FunctionName: !Ref InvalidateCloudFront Action: \"lambda:InvokeFunction\" Principal: \"events.amazonaws.com\" SourceArn: !GetAtt EventCloudFrontLambda.Arn Test Updating The Pull-request Code Let‚Äôs make some changes, if you cloned my repository you can change the index.json file\nand replace ‚ÄúHello World War 3! with ‚ÄúHello World Peace‚Äù\nand let‚Äôs wait for the builds to run successfully and recheck again our preview\nChallenge For You As our pull request creates a directory on S3, it is a waste of storage and money if we leave the directory on S3 after merging the pull request.\nSo the challenge will be creating a GitHub action workflow that will delete the folder from S3 after merging the pull request. one of the requirements is using AWS OpenID Connect.\nDon‚Äôt hesitate to email me, It will be a pleasure for me to review your work üòä\nSummary In this article, we walked into different AWS Services(CodeBuild, Cloudfront,S3), we understand the mechanism of AWS IAM finally we learned how to create and deploy our services with Cloudformation\nThanks for your time, stay tuned for new articles.\n","wordCount":"3504","inLanguage":"en","image":"//localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2023-01-10T11:39:04+01:00","dateModified":"2023-01-10T11:39:04+01:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"//localhost:1313/posts/deployment-preview-with-aws-cloudfront/"},"publisher":{"@type":"Organization","name":"chown u+r mind","logo":{"@type":"ImageObject","url":"//localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//localhost:1313/ accesskey=h title="chown u+r mind (Alt + H)"><img src=//localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>chown u+r mind</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=//localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=//localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//localhost:1313/>Home</a>&nbsp;¬ª&nbsp;<a href=//localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Deployment Preview with AWS CloudFront</h1><div class=post-meta><span title='2023-01-10 11:39:04 +0100 CET'>January 10, 2023</span>&nbsp;¬∑&nbsp;17 min&nbsp;¬∑&nbsp;3504 words&nbsp;¬∑&nbsp;Me</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#introduction><strong>Introduction</strong></a></li></ul></li><li><a href=#creating-ci-pipeline><strong>Creating CI Pipeline</strong></a><ul><li><a href=#give-codebuild-the-required-permissions><strong>Give CodeBuild the required permissions</strong></a></li><li><a href=#access-and-store-codebuild-logs><strong>Access and Store CodeBuild Logs</strong></a></li><li><a href=#access-and-store-react-builds><strong>Access and Store React Builds</strong></a></li><li><a href=#codebuild-ci-environment><strong>CodeBuild CI Environment</strong></a></li><li><a href=#codebuild-trigger-and-repo-linking><strong>CodeBuild Trigger and Repo Linking</strong></a></li><li><a href=#ci-logs-public-visibility-to-users><strong>CI logs Public Visibility To Users</strong></a></li><li><a href=#sum-it-up><strong>Sum It Up</strong></a></li></ul></li><li><a href=#serving-content-with-cloudfront><strong>Serving Content With CloudFront</strong></a><ul><li><a href=#creating-cloudfront><strong>Creating CloudFront</strong></a></li><li><a href=#choose-the-right-path-with-lambdaedge><strong>Choose The Right Path with Lambda@Edge</strong></a></li><li><a href=#a-little-demo><strong>A Little Demo</strong></a></li><li><a href=#test-updating-the-pull-request-nbspcode><strong>Test Updating The Pull-request ¬†Code</strong></a></li></ul></li><li><a href=#challenge-for-you><strong>Challenge For You</strong></a></li><li><a href=#summary><strong>Summary</strong></a></li></ul></nav></div></details></div><div class=post-content><h3 id=introduction><strong>Introduction</strong><a hidden class=anchor aria-hidden=true href=#introduction>#</a></h3><p>Deploy Previews allow you and your team to experience changes to any part of your site without having to publish them to production.</p><p>With a deploy previews feature you and your teammates can see the changes of every pull request you make without merging it, this will reduce the burden of rolling back the environment when bugs happen as you can review the changes before.</p><p>In this tutorial, you‚Äôll learn about creating a CI pipeline with CodeBuild that gets triggered on every pull request creation or update, for every build we host react build folder on an S3 bucket and serve it with Cloudfront, finally after merging the pull request, we delete the build folder from S3.</p><p>In the end, this tutorial will expand your knowledge of AWS Services and help you speed up your development and deployment process.</p><p>Before starting, here is a playlist to enjoy reading with</p><p>To accomplish this tutorial, you‚Äôll need:</p><ul><li>an AWS account with administrative permissions</li><li>an AWS CLI with a minimum version of 2.4.6</li><li>a runnable React app hosted on GitHub</li><li>basic knowledge of YAML file structure</li><li>clone this <a href=https://github.com/hamzabouissi/simple-react-app>simple react app</a></li></ul><h2 id=creating-ci-pipeline><strong>Creating CI Pipeline</strong><a hidden class=anchor aria-hidden=true href=#creating-ci-pipeline>#</a></h2><p>To build a resilient system, you need to add tests on your code then run them locally and on every push to version control. In this step, you will build a CI pipeline that triggers every pull request creation or update on your GitHub repository, the pipeline will run the desired tests and return a badge containing the status of the tests to your GitHub.</p><p>Create the file ¬†pull-request.yml ¬†in your text editor:</p><pre><code>nano pull-request.yml
</code></pre><p>Add the following CloudFormation code to the file, which builds a CodeBuildProject that defines a CI pipeline with GitHub integration:</p><pre><code>Resources:
  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: FrontBuildOnPull
      ServiceRole: !GetAtt BuildProjectRole.Arn
      LogsConfig:
        CloudWatchLogs:
          GroupName: !Ref BuildLogGroup
          Status: ENABLED
          StreamName: front_pull_request
      EncryptionKey: &quot;alias/aws/s3&quot;
      Artifacts:
        Type: S3
        Location: !Ref ArtifactBucket
        Name: FrontPullRequest
        OverrideArtifactName: true
        EncryptionDisabled: true
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_MEDIUM
        Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0
       
      Source:
        Type: GITHUB
        Location: &quot;https://github.com/projectX/repoY&quot;
        ReportBuildStatus: true
      Triggers:
        BuildType: BUILD
        Webhook: true
        FilterGroups:
          - - Type: EVENT
              Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED
      Visibility: PUBLIC_READ
      ResourceAccessRole: !Ref PublicReadRole
</code></pre><p>I will briefly explain the CloudFormation template structure, so you can get a general understanding of CloudFormation files that guides you through the next steps.</p><p>The majority of CloudFormation template files will contain Parameters(Optional) and Resources(Required), Outputs(Optional), each block on the Resources is a Service, and every Service contains Type and Properties. The type is referred to as AWS Service or a Custom Function and each Type has a different set of properties.</p><p>Let‚Äôs analyze the above Code to understand better. Here we have a Resources block that contains three Services. The CodeBuildProject refers to AWS::CodeBuild::Project which is an AWS Service for <a href=https://aws.amazon.com/codebuild/>CodeBuild</a>. The CodeBuild has a set of properties, you can find them here <a href=https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-codebuild-project.html>properties</a>, I will explain each property functionality and why we‚Äôre adding it.</p><h3 id=give-codebuild-the-required-permissions><strong>Give CodeBuild the required permissions</strong><a hidden class=anchor aria-hidden=true href=#give-codebuild-the-required-permissions>#</a></h3><p>For CodeBuild to work we need to assign the ServiceRole an IAM Role to give CodeBuild the right to access other AWS services like secrets, S3, and logs.</p><pre><code>  ...
  ServiceRole: !GetAtt BuildProjectRole.Arn
  ...
  ...
</code></pre><p>BuildProjectRole is a role that assumes the principal ‚Äúcodebuild.amazonaws.com‚Äù the permission to use a set of services on our behalf of us, more reading about <a href=https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-role.html>AWS::IAM::ROLE</a></p><p>After, we need to ask ourselves what services CodeBuild must have access to and what we want to access on each of the services:</p><ul><li>Codebuild needs to create and update the test reports.</li><li>CodeBuild needs to store the CI process logs inside a logs group.</li><li>CodeBuild needs to access the secrets manager to get some secret credentials ex: CYPRESS_KEY. - CodeBuild needs to get and store React build folder on S3.</li></ul><p>Now after we defined our requirements, we create BuildProjectPolicy which is an <a href=https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-iam-policy.html>AWS::IAM::Policy</a> for BuildProjectRole that contains the list of statements, and each statement is composed of a set of actions.</p><pre><code>BuildProjectRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - codebuild.amazonaws.com
            Action:
              - sts:AssumeRole
      
  BuildProjectPolicy:
    Type: AWS::IAM::Policy
    DependsOn: BuildProjectRole
    Properties:
      PolicyName: !Sub ${AWS::StackName}-CodeBuildPolicy
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - codebuild:CreateReportGroup
              - codebuild:CreateReport
              - codebuild:UpdateReport
              - codebuild:BatchPutTestCases
              - codebuild:BatchPutCodeCoverages
            # Create and update test report

            Resource: &quot;*&quot;
          - Effect: Allow
            Action:
              - s3:PutObject
              - s3:GetObject
              - s3:GetObjectVersion
            # Get and store React build folder on S3

            Resource: &quot;*&quot;
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            # Store the CI process logs inside a logs group
            Resource: arn:aws:logs:*:*:*
          - Effect: Allow
            Action:
              - secretsmanager:*
            # Get secret creedentials ex: CYPRESS_KEY
            
            Resource: &quot;*&quot;
      Roles:
        - !Ref BuildProjectRole
</code></pre><h3 id=access-and-store-codebuild-logs><strong>Access and Store CodeBuild Logs</strong><a hidden class=anchor aria-hidden=true href=#access-and-store-codebuild-logs>#</a></h3><p>Logs are an important key of DevOps because it adds the visibility aspect to the infrastructure, so gather logs as much as you can. In our case, to enable logs for CodeBuild project we create LogsConfig property.</p><pre><code>  ...
  ...
  LogsConfig:
    CloudWatchLogs:
      GroupName: !Ref BuildLogGroup
      Status: ENABLED
      StreamName: front_pull_request
  ...
  ...
</code></pre><p>Now, we need to create a LogGroup to which CodeBuild pushes logs to</p><pre><code>BuildLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: frontend_build_on_pull
      RetentionInDays: 7
</code></pre><p>RetentionInDays is the period after which the logs expire.</p><h3 id=access-and-store-react-builds><strong>Access and Store React Builds</strong><a hidden class=anchor aria-hidden=true href=#access-and-store-react-builds>#</a></h3><p>After successfully building and testing the project, we should store the build folder on S3 so we can access it again when the developer wants to see his changes. So we create an Artifacts property that stores build on an S3 bucket called ‚ÄúArtifactBucket‚Äù</p><pre><code>  ...
  ...
  Artifacts:
    Type: S3
    Location: !Ref ArtifactBucket
    Name: FrontPullRequest
    OverrideArtifactName: true
    EncryptionDisabled: true
  ...
  ...
</code></pre><p>OverrideArtifactName we use to customize the path where we store the builds.</p><p>EncryptionDisabled we disabled it because we don‚Äôt need custom encryption in our case, we will be using the default one instead.</p><pre><code>ArtifactBucket:
  Type: 'AWS::S3::Bucket'
  DeletionPolicy: Delete
  Properties:
    BucketName: &quot;some-random-unique-bucket-name&quot;
    BucketEncryption:
      ServerSideEncryptionConfiguration:
        - ServerSideEncryptionByDefault:
            SSEAlgorithm: AES256
    PublicAccessBlockConfiguration:
      BlockPublicAcls: true
      BlockPublicPolicy: true
      IgnorePublicAcls: true
      RestrictPublicBuckets: true
</code></pre><p>ArtifactBucket is a resource block that refers to AWS::S3::Bucket, also we should add some properties to restrict public access to build folders and define how the data must be encrypted when it gets stored.</p><p>Name: you need to change to your unique bucket name, the name must be unique across all AWS buckets.</p><p>BucketEncryption we use Amazon S3 server-side encryption which uses 256-bit Advanced Encryption Standard(AES256).</p><p>PublicAccessBlockConfiguration this property blocks all public access to the public and ignores any policy that allows public visibility of the bucket.</p><h3 id=codebuild-ci-environment><strong>CodeBuild CI Environment</strong><a hidden class=anchor aria-hidden=true href=#codebuild-ci-environment>#</a></h3><p>For the CI to work, you must provide information about the CI environment. A build environment represents a combination of the operating system, programming language runtime, and tools that CodeBuild uses to run a build.</p><pre><code>  ...
  ...
  Environment:
    Type: LINUX_CONTAINER
    ComputeType: BUILD_GENERAL1_MEDIUM
    Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0
  ...
</code></pre><p>Type this is the OS type, which is Linux for our case.</p><p>ComputeType: this provides the CodeBuild with information about the computing resources it‚Äôs allowed to use (7 GB Memory,4vCPU,128GB Disk ).</p><p>Image: A docker image to use during the build which provides the environment with a set of tools and runtimes, here is the <a href=https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-available.html>documentation</a> for better details</p><h3 id=codebuild-trigger-and-repo-linking><strong>CodeBuild Trigger and Repo Linking</strong><a hidden class=anchor aria-hidden=true href=#codebuild-trigger-and-repo-linking>#</a></h3><p>To fire up the build process whenever a pull request is created or updated, you need to add two properties: Source, Triggers</p><pre><code>  ...
  ...
  Source:
    Type: GITHUB
    Location: &quot;https://github.com/projectX/repoY&quot;
    ReportBuildStatus: true
  Triggers:
    BuildType: BUILD
    Webhook: true
    FilterGroups:
      - - Type: EVENT
          Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED
  ...
  ...
</code></pre><p>Source defines the type of version control and the location, you need to change the Location property to your desired repository, on the other side to report the build status back to version control(Github) you turn ReportBuildStatus to true. Triggers specify webhooks that trigger The AWS CodeBuild build.</p><p>To allow Codebuild access to your repository, you need to create a personal access token and pass it to CodeBuild so it can access your repo on your behalf, This can be done in two steps:</p><p>1- Generate a personal token from your GitHub account:</p><p>Visit the <a href=https://github.com/settings/tokens/new>Personal access tokens Github page</a>, then select ‚ÄúFull control of private repositories‚Äù and ‚ÄúFull control of repository hooks‚Äù and click Generate token.</p><p>2- Pass down the generated token to AWS Codebuild credentials: Run the following command to generate an import-source-credentials.json ¬†file on your local :</p><pre><code>aws codebuild import-source-credentials --generate-cli-skeleton
</code></pre><p>After, we need to modify ¬†import-source-credentials.json ¬†and fill it with your credentials:</p><ul><li><p>auth_type: PERSONAL_ACCESS_TOKEN</p></li><li><p>serverType: GITHUB</p></li><li><p>username: your GitHub username</p></li><li><p>token: the generated token from the previous step.</p><p>aws codebuild import-source-credentials &ndash;cli-input-json file://import-source-credentials.json</p></li></ul><p>To test that your command runs successfully, run the following command to list your CodeBuild credentials:</p><pre><code>aws codebuild list-source-credentials
</code></pre><p>Now when CodeBuild starts running it will search in your source code for a file named buildspec.yml, by definition :</p><p>A <em>buildspec</em> is a collection of build commands and related settings, in YAML format, that CodeBuild uses to run a build.</p><p>Here is an example of buildspec.yml from our demo app :</p><pre><code>version: 0.2

phases:
  install:
    commands:
      - npm install 
  pre_build:
    on-failure: ABORT
    commands:
      - echo &quot;run some pre-check&quot;
      #- npm run format:check
      #- npm run lint:check
  build:
    on-failure: ABORT
    commands:
      - echo &quot;run tests&quot;
      # - npm run-script start &amp; npx wait-on http://localhost:3000
      # - npx cypress run --record --key ${CYPRESS_KEY}

  post_build:
    commands:
      - |
          npm run build

artifacts:
  # include all files required to run application
  # we include only the static build files
  files:
    - '**/*'
  name: $CODEBUILD_WEBHOOK_TRIGGER
  base-directory: 'dist'
</code></pre><p>Our CI contains different phases (install, pre_build ‚Ä¶etc), finally, post_build will run when all the previous steps exited successfully.</p><p>post_build will create a ¬†dist folder and then CodeBuild will upload the dist folder to S3 under CODEBUILD_WEBHOOK_TRIGGER path that will be ¬†/pr/{pr_number}.</p><p>For example, if a pull request gets created with the number 1, then after CI builds successfully the build folder will get stored on ArtifactBucket under path <strong>/pr/1/</strong>.</p><h3 id=ci-logs-public-visibility-to-users><strong>CI logs Public Visibility To Users</strong><a hidden class=anchor aria-hidden=true href=#ci-logs-public-visibility-to-users>#</a></h3><p>The following property gives developers access to see build logs without having an AWS account :</p><pre><code>...
...
Visibility: PUBLIC_READ
ResourceAccessRole: !Ref PublicReadRole
...
</code></pre><p>then the PublicReadRole must allow access to logs and S3</p><pre><code>  PublicReadRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: ['sts:AssumeRole']
            Effect: Allow
            Principal:
              Service: [codebuild.amazonaws.com]
        Version: '2012-10-17'
      Path: /

  PublicReadPolicy:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyName: PublicBuildPolicy
      PolicyDocument:
        Version: &quot;2012-10-17&quot;
        Statement:
          - Effect: Allow
            Action:
              - &quot;logs:GetLogEvents&quot;
            Resource:
              - !Sub &quot;arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${BuildLogGroup}:*&quot;
          - Effect: Allow
            Action:
              - &quot;s3:GetObject&quot;
              - &quot;s3:GetObjectVersion&quot;
            Resource:
              - Fn::Sub:
                - &quot;${ArtifcatArn}/*&quot;
                - {ArtifcatArn: !GetAtt ArtifactBucket.Arn}
      Roles:
        - !Ref PublicReadRole
</code></pre><h3 id=sum-it-up><strong>Sum It Up</strong><a hidden class=anchor aria-hidden=true href=#sum-it-up>#</a></h3><p>After you understand the full picture of CodeBuild Service and its dependency, you can edit pull-request.yml:</p><pre><code>nano pull-request.yml
</code></pre><p>replace its content with the following code</p><pre><code>Resources:
  CodeBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: FrontBuildOnPull
      ServiceRole: !GetAtt BuildProjectRole.Arn
      LogsConfig:
        CloudWatchLogs:
          GroupName: !Ref BuildLogGroup
          Status: ENABLED
          StreamName: front_pull_request
      EncryptionKey: &quot;alias/aws/s3&quot;
      Artifacts:
        Type: S3
        Location: !Ref ArtifactBucket
        Name: FrontPullRequest
        OverrideArtifactName: true
        EncryptionDisabled: true
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_MEDIUM
        Image: aws/codebuild/amazonlinux2-x86_64-standard:4.0
       
      Source:
        Type: GITHUB
        Location: &quot;https://github.com/projectX/repoY&quot;
        ReportBuildStatus: true
      Triggers:
        BuildType: BUILD
        Webhook: true
        FilterGroups:
          - - Type: EVENT
              Pattern: PULL_REQUEST_CREATED,PULL_REQUEST_UPDATED
      Visibility: PUBLIC_READ
      ResourceAccessRole: !Ref PublicReadRole

  BuildProjectRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - codebuild.amazonaws.com
            Action:
              - sts:AssumeRole
      
  BuildProjectPolicy:
    Type: AWS::IAM::Policy
    DependsOn: BuildProjectRole
    Properties:
      PolicyName: !Sub ${AWS::StackName}-CodeBuildPolicy
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - codebuild:CreateReportGroup
              - codebuild:CreateReport
              - codebuild:UpdateReport
              - codebuild:BatchPutTestCases
              - codebuild:BatchPutCodeCoverages
            # Create and update test report

            Resource: &quot;*&quot;
          - Effect: Allow
            Action:
              - s3:PutObject
              - s3:GetObject
              - s3:GetObjectVersion
            # Get and store React build folder on S3

            Resource: &quot;*&quot;
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            # Store the CI process logs inside a logs group
            Resource: arn:aws:logs:*:*:*
          - Effect: Allow
            Action:
              - secretsmanager:*
            # Get secret creedentials ex: CYPRESS_KEY
            
            Resource: &quot;*&quot;
      Roles:
        - !Ref BuildProjectRole

  BuildLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: frontend_build_on_pull
      RetentionInDays: 7
  
  ArtifactBucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Delete
    Properties:
      BucketName: &quot;some-random-unique-bucket-name&quot;
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
  
  PublicReadRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Action: ['sts:AssumeRole']
            Effect: Allow
            Principal:
              Service: [codebuild.amazonaws.com]
        Version: '2012-10-17'
      Path: /

  PublicReadPolicy:
    Type: 'AWS::IAM::Policy'
    Properties:
      PolicyName: PublicBuildPolicy
      PolicyDocument:
        Version: &quot;2012-10-17&quot;
        Statement:
          - Effect: Allow
            Action:
              - &quot;logs:GetLogEvents&quot;
            Resource:
              - !Sub &quot;arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${BuildLogGroup}:*&quot;
          - Effect: Allow
            Action:
              - &quot;s3:GetObject&quot;
              - &quot;s3:GetObjectVersion&quot;
            Resource:
              - Fn::Sub:
                - &quot;${ArtifcatArn}/*&quot;
                - {ArtifcatArn: !GetAtt ArtifactBucket.Arn}
      Roles:
        - !Ref PublicReadRole
</code></pre><p>To test our code, move into the pull-request.yml file path and run</p><pre><code>aws cloudformation create-stack --stack-name pull-request-preview-stack --template-body file://pull-request.yml --capabilities CAPABILITY_NAMED_IAM
</code></pre><p>Now visit <a href=https://console.aws.amazon.com/cloudformation/home>Cloudformation Console</a> and you should see a stack with the name pull-request-preview-stack and its status CREATE_IN_PROGRESS or CREATE_COMPLETE</p><h2 id=serving-content-with-cloudfront><strong>Serving Content With CloudFront</strong><a hidden class=anchor aria-hidden=true href=#serving-content-with-cloudfront>#</a></h2><p>CloudFront is a content delivery network(CDN), CDN can speed up the serving of your static content by caching in the edges that are near you, it is less expensive and it allows you to add a TLS certificate(HTTP) and domain to your static content.</p><p>On the other side, we don‚Äôt need all of these things but what we want from CloudFront is Lambda@Edge which will allow us to redirect requests by the header to right S3 bucket folder. To explain more, let‚Äôs suppose we made 2 pull-request by numbers 121,122, after 2 of them are tested and built successfully, they will get stored in a folder named pr on the Artifact Bucket with the following structure:</p><p>pr/</p><p>121/</p><ul><li>assets</li><li>index.html</li><li>‚Ä¶</li><li>‚Ä¶</li></ul><p>122/</p><ul><li>assets</li><li>index.html</li><li>‚Ä¶</li><li>‚Ä¶</li></ul><p>Now when Lambda@Edge comes to play, every request that comes to the CloudFront host(which is a random subdomain under CloudFront xxxxx.cloudfront.net) with a pull-request header and value 122 will be redirected to the folder ‚Äú122‚Äù to serve ‚Äú122‚Äù pull request contents.</p><p>In this section, you will learn how to serve S3 content from a CDN and customize users requests by different criteria like (header,query-params‚Ä¶etc) and also build a trigger whenever a build runs successfully, it clears the cache of a specific pull request on the CDN for the new contents.</p><h3 id=creating-cloudfront><strong>Creating CloudFront</strong><a hidden class=anchor aria-hidden=true href=#creating-cloudfront>#</a></h3><p>Let‚Äôs edit pull-request.yml</p><pre><code>nano pull-request.yml
</code></pre><p>and add a CloudFront Distribution Service that will primarily serve index.html from ArtifactBucket</p><pre><code>Distribution:
  Type: AWS::CloudFront::Distribution
  Properties:
    DistributionConfig:
      Origins:
        - DomainName: !Sub ${ArtifactBucket}.s3.${AWS::Region}.amazonaws.com
          Id: S3Origin
          S3OriginConfig:
            OriginAccessIdentity: !Sub origin-access-identity/cloudfront/${OriginAccessIdentity}
      Enabled: true
      DefaultRootObject: index.html
      Logging:
        Bucket: !Sub ${DistributionBucket}.s3.${AWS::Region}.amazonaws.com
      DefaultCacheBehavior:
        TargetOriginId: S3Origin
        CachePolicyId: !Ref DistributionCachingPolicy
        ViewerProtocolPolicy: https-only
      PriceClass: PriceClass_100
</code></pre><p>Cloudfront has 4 major properties that we will explain briefly</p><p>Origins: This property refers to where CloudFront retrieves the content, we will be adding only Artifact Bucket, also there is a sub-property OriginAccessIdentity that restricts access to ArtifactBucket bucket only from CloudFront.</p><p>DefaultRootObject: The default file that CloudFront will render from the bucket</p><p>PriceClass: To how many regions should our content get cached? we choose PriceClass_100 that‚Äôs the minimum value because we don‚Äôt care about that.</p><p>Logging: We should collect access logs, So we store them in a bucket ‚ÄúDistributionBucket‚Äù</p><p>DefaultCacheBehavior is a required property so we will add it, but we don‚Äôt need any caching behavior from CloudFront to test the pull requests. DefaultCacheBehavior contains 3 required attributes:</p><ul><li><p><strong>TargetOriginId</strong> points to one of our Origins which is S3Origin the only origin we have.</p></li><li><p><strong>ViewerProtocolPolicy</strong> controls whether the user is redirected to HTTPS or uses HTTP or both, we chose https-only.</p></li><li><p><strong>CachePolicyId</strong> , is an important property because we need to allow CloudFront to pass certain headers to Lambda@Edge and the available <a href=https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-cache-policies.html#managed-cache-policies-list>managed cache policies</a> don‚Äôt allow that, so creating a custom cache policy will help. here is the code for the custom cache policy that allows passing the pull-request header to Lambda@Edge.</p><p>DistributionCachingPolicy:
Type: AWS::CloudFront::CachePolicy
Properties:
CachePolicyConfig:
Comment: &ldquo;Allow pass of header and query params to cloudfront&rdquo;
DefaultTTL: 86400
MaxTTL: 31536000
MinTTL: 80400
Name: CacheForHeaderAndQuery
ParametersInCacheKeyAndForwardedToOrigin:
CookiesConfig:
CookieBehavior: none
EnableAcceptEncodingGzip: false
HeadersConfig:
HeaderBehavior: whitelist
Headers:
- pull-request
QueryStringsConfig:
QueryStringBehavior: all</p></li></ul><p>Now the problem we‚Äôre facing is that our pull requests content is stored under the PR folder so we cannot serve them as Cloudfront doesn‚Äôt allow dynamic selection of contents. So the solution is rerouting the user request before it reaches the S3 bucket and choosing the right path depending on the custom header(pull-request) he passes on the request.</p><h3 id=choose-the-right-path-with-lambdaedge><strong>Choose The Right Path with Lambda@Edge</strong><a hidden class=anchor aria-hidden=true href=#choose-the-right-path-with-lambdaedge>#</a></h3><p>To add Lambda@Edge to CloudFront we will modify DefaultCacheBehavior to look like this:</p><pre><code>DefaultCacheBehavior:
  TargetOriginId: S3Origin
  ViewerProtocolPolicy: redirect-to-https
  CachePolicyId: !Ref DistributionCachingPolicy
  LambdaFunctionAssociations:
    - EventType: 'origin-request'
      LambdaFunctionARN: !Ref VersionedLambdaFunction
</code></pre><p>Let‚Äôs create the lambda function, the programming language will be <strong>python</strong> :</p><pre><code>LambdaFunction:
  Type: 'AWS::Lambda::Function'
  Properties:
    FunctionName: &quot;cloudfront_lambda&quot;
    Code:
      ZipFile: !Sub |
        import re
        import boto3 

        def handler(event, context):
            client = boto3.client(&quot;s3&quot;)
            bucket = &quot;front-end-preview-bucket&quot;
            response = client.list_objects_v2(Bucket=bucket,Prefix=&quot;pr/&quot;,Delimiter=&quot;/&quot;)
            prs = [p['Prefix'].split('/')[1] for p in response['CommonPrefixes']]

            request = event['Records'][0]['cf']['request']
            print(request)

            headers = request['headers']
            pr = headers.get('pull-request',None)
            
            
            if pr is None:
              print(f&quot;{pr} not found&quot;)
              response = {
                'status': '404',
                'statusDescription': 'No Found',
              }
              return response
            
            pr = pr[0]['value']

            if not pr.isdigit() or not (pr in prs):
              print(f&quot;{pr} not good&quot;)
              response = {
                'status': '404',
                'statusDescription': 'No Found',
              }
              return response

            pr = int(pr)
            request['uri'] = f&quot;/pr/{pr}{request['uri']}&quot;

            print(request)
            return request

    Handler: 'index.handler'
    MemorySize: 128
    Role: !GetAtt 'LambdaRole.Arn'
    Runtime: 'python3.9'
    Timeout: 5

  LambdaRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - 'lambda.amazonaws.com'
            - 'edgelambda.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
        - PolicyName: FetchContentFromBucket
          PolicyDocument:
            Version: &quot;2012-10-17&quot;
            Statement:
              - Effect: Allow
                Action:
                  - &quot;s3:GetObject&quot;
                  - &quot;s3:ListBucket&quot;
                  - &quot;s3:GetObjectVersion&quot;
                Resource:
                  - Fn::Sub:
                    - &quot;${ArtifcatArn}/*&quot;
                    - {ArtifcatArn: !GetAtt ArtifactBucket.Arn}
                 
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      - &quot;arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole&quot;
</code></pre><p>To summarize what function do, we fetch all current pull requests that are stored on the bucket and whenever a user makes a request, we check the header(pull-request) value and see if it‚Äôs available, if yes we rewrite the request URI to <strong>‚Äú/pr/{pr}{request[‚Äòuri‚Äô]}‚Äù</strong>, if no we return 404 response.</p><p>Also, we assign Lambda different policies, some are managed policies like :</p><ul><li>AWSLambdaBasicExecutionRole</li><li>AWSLambdaVPCAccessExecutionRole</li></ul><p>and others are custom like FetchContentFromBucket to query React build folder from ArtifactBucket.</p><h3 id=a-little-demo><strong>A Little Demo</strong><a hidden class=anchor aria-hidden=true href=#a-little-demo>#</a></h3><p>After understanding what each service does, we update our pull-request.yml file with the above code. then we update cloud formation with the following command:</p><pre><code>aws cloudformation update-stack --stack-name pull-request-preview-stack --template-body file://pull-request.yml --capabilities CAPABILITY_NAMED_IAM
</code></pre><p>Now visit <a href=https://console.aws.amazon.com/cloudformation/home>Cloudformation Console</a> and you should see a stack with the name pull-request-preview-stack and its status <strong>UPDATE_IN_PROGRESS</strong> or <strong>UPDATE_COMPLETE</strong>.</p><p>To get the CloudFront endpoint Click on pull-request-preview-stack on Cloudformation Console and Click Outputs</p><p>What‚Äôs missing now, is creating a pull request in our repository. first, we need a new branch</p><pre><code>git switch -c feature/test_preview
</code></pre><p>then let‚Äôs make some changes and finally add, commit, push</p><pre><code>git add .
git commit -m &quot;it's getting darker :black:&quot;
git push --set-upstream origin feature/test_preview
</code></pre><p>Now let‚Äôs wait until the tests pass successfully üëÄ</p><p>If you visit the CloudFront Endpoint you will get a 404 page, this happens because you didn‚Äôt pass a pull-request number as a header. So to achieve this we need to install a chrome extension ‚Äú<a href=https://modheader.com/>mobheader</a>‚Äù</p><p>you replace 271 with your pull request number that you find on the Github pull request page</p><p>Refresh now, Taddaaaa üéä</p><p>Now, Let&rsquo;s suppose that you made a pull request and requested one of your teammates to make a review for you and he reclaimed something buggy is happening, so you went to investigate the issue and solved it and now you‚Äôre pushing the updates. After your CI builds and tests successfully, you visit the CloudFront URL and you find the bug still exists, why ?!.</p><p>Well it‚Äôs because CloudFront caches the build folder on its servers and you need to invalidate the cache from the servers then CloudFront will request the files again from S3</p><p>So the approach will be creating a Lambda Function that gets triggered whenever the builds run successfully, The function takes CloudFront DistributionId as an environment variable and make an invalidation request to /pr/{pr_number} subfolder</p><pre><code>EventCloudFrontLambda:
  Type: 'AWS::Events::Rule'
  Properties:
    Description: Invalidate Cloudfront after a successful build
    State: ENABLED
    EventPattern:
      source:
        - aws.codebuild
      detail-type:
        - CodeBuild Build State Change
      detail:
        build-status:
          - SUCCEEDED
        project-name:
          - !Ref CodeBuildProject
    Targets:
      -
        Arn: !GetAtt InvalidateCloudFront.Arn
        Id: &quot;TargetFunctionV1&quot;

  InvalidateCloudFront:
    Type: 'AWS::Lambda::Function'
    Properties:
      FunctionName: &quot;invalidate_cloudfront_from_codebuild_lambda&quot;
      Environment:
        Variables:
          DistributionId: !GetAtt Distribution.Id
      Code:
        ZipFile: !Sub |
          import boto3
          import uuid
          import os

          def handler(event, context):
              print(event)
              artifict = event['detail']['additional-information']['artifact']['location']
              pr = artifict.split(&quot;/&quot;)[2]

              distribution_id = os.getenv(&quot;DistributionId&quot;)

              print(distribution_id)

              client = boto3.client(&quot;cloudfront&quot;)
              response = client.create_invalidation(
                  DistributionId=distribution_id,
                  InvalidationBatch={
                      'Paths': {
                          'Quantity': 1,
                          'Items': [
                              f'/pr/{pr}/*',
                          ]
                      },
                      'CallerReference': str(uuid.uuid4())
                  }
              )

              return {&quot;status&quot;:200}
      Handler: 'index.handler'
      MemorySize: 128
      Role: !GetAtt 'LambdaRole.Arn'
      Runtime: 'python3.9'
      Timeout: 15

  InvalidateCloudFrontLogs:
    Type: AWS::Logs::LogGroup
    DependsOn: InvalidateCloudFront
    Properties:
      LogGroupName: !Sub &quot;/aws/lambda/${InvalidateCloudFront}&quot;
      RetentionInDays: 7

  PermissionForEventsToInvokeLambda:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref InvalidateCloudFront
      Action: &quot;lambda:InvokeFunction&quot;
      Principal: &quot;events.amazonaws.com&quot;
      SourceArn: !GetAtt EventCloudFrontLambda.Arn
</code></pre><h3 id=test-updating-the-pull-request-nbspcode><strong>Test Updating The Pull-request ¬†Code</strong><a hidden class=anchor aria-hidden=true href=#test-updating-the-pull-request-nbspcode>#</a></h3><p>Let‚Äôs make some changes, if you cloned my repository you can change the index.json file</p><p>and replace ¬†‚ÄúHello World War 3! ¬†with ‚ÄúHello World Peace‚Äù</p><p>and let‚Äôs wait for the builds to run successfully and recheck again our preview</p><h2 id=challenge-for-you><strong>Challenge For You</strong><a hidden class=anchor aria-hidden=true href=#challenge-for-you>#</a></h2><p>As our pull request creates a directory on S3, it is a waste of storage and money if we leave the directory on S3 after merging the pull request.</p><p>So the challenge will be creating a GitHub action workflow that will delete the folder from S3 after merging the pull request. one of the requirements is using AWS OpenID Connect.</p><p>Don‚Äôt hesitate to email me, It will be a pleasure for me to review your work üòä</p><h2 id=summary><strong>Summary</strong><a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>In this article, we walked into different AWS Services(CodeBuild, Cloudfront,S3), we understand the mechanism of AWS IAM finally we learned how to create and deploy our services with Cloudformation</p><p>Thanks for your time, stay tuned for new articles.</p></div><footer class=post-footer><ul class=post-tags><li><a href=//localhost:1313/tags/aws/>AWS</a></li><li><a href=//localhost:1313/tags/cloudfront/>CloudFront</a></li><li><a href=//localhost:1313/tags/ci/cd-pipeline/>CI/CD Pipeline</a></li><li><a href=//localhost:1313/tags/frontend/>FrontEnd</a></li></ul><nav class=paginav><a class=prev href=//localhost:1313/posts/the-beginning/><span class=title>¬´ Prev</span><br><span>GCP -> AWS Migration: The Beginning</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on x" href="https://x.com/intent/tweet/?text=Deployment%20Preview%20with%20AWS%20CloudFront&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f&amp;hashtags=AWS%2cCloudFront%2cCI%2fCDpipeline%2cFrontEnd"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f&amp;title=Deployment%20Preview%20with%20AWS%20CloudFront&amp;summary=Deployment%20Preview%20with%20AWS%20CloudFront&amp;source=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on reddit" href="https://reddit.com/submit?url=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f&title=Deployment%20Preview%20with%20AWS%20CloudFront"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on facebook" href="https://facebook.com/sharer/sharer.php?u=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on whatsapp" href="https://api.whatsapp.com/send?text=Deployment%20Preview%20with%20AWS%20CloudFront%20-%20%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on telegram" href="https://telegram.me/share/url?text=Deployment%20Preview%20with%20AWS%20CloudFront&amp;url=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Deployment Preview with AWS CloudFront on ycombinator" href="https://news.ycombinator.com/submitlink?t=Deployment%20Preview%20with%20AWS%20CloudFront&u=%2f%2flocalhost%3a1313%2fposts%2fdeployment-preview-with-aws-cloudfront%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=//localhost:1313/>chown u+r mind</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>