<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AWS Copilot on chown u&#43;r mind</title>
    <link>//localhost:1313/tags/aws-copilot/</link>
    <description>Recent content in AWS Copilot on chown u&#43;r mind</description>
    <image>
      <title>chown u&#43;r mind</title>
      <url>//localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>//localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.133.0</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Apr 2023 16:12:38 +0100</lastBuildDate>
    <atom:link href="//localhost:1313/tags/aws-copilot/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GCP -&gt; AWS Migration: Confession</title>
      <link>//localhost:1313/posts/confession/</link>
      <pubDate>Tue, 25 Apr 2023 16:12:38 +0100</pubDate>
      <guid>//localhost:1313/posts/confession/</guid>
      <description>(Knock on the door)
(door opens)(some background noise of the company like people shatter or talk)
Yeah, Come In
Hey
Hey
Hey, my Junior friend, have a seat.
Thanks
It&amp;rsquo;s been 2 weeks since I assigned you the project, how it&amp;rsquo;s going?
Good, I&amp;rsquo;m doing good, I just finished a few tasks and as you asked about my progress.
So, can you tell me how much progress you have made?</description>
      <content:encoded><![CDATA[<p>(Knock on the door)</p>
<p>(door opens)(some background noise of the company like people shatter or talk)</p>
<p>Yeah, Come In</p>
<p>Hey</p>
<p>Hey</p>
<p>Hey, my Junior friend, have a seat.</p>
<p>Thanks</p>
<p>It&rsquo;s been 2 weeks since I assigned you the project, how it&rsquo;s going?</p>
<p>Good, I&rsquo;m doing good, I just finished a few tasks and as you asked about my progress.</p>
<p>So, can you tell me how much progress you have made?</p>
<p>I think am nearly 40%, I somehow finished creating the dev environment, so I can test with developers the performance and durability of the infrastructure.</p>
<p>What about PostgreSQL, Redis, Configuration and Secrets Management? And I saw your email about using AWS AURORA, did you figure out the answer ?</p>
<p>I deployed the database as an RDS, well I didn&rsquo;t find a real benefit in using Aurora for the dev environment, and also it is somehow expensive, but maybe we can use it on the prod environment as it offers scalability. For Redis, AWS has a fully managed service called Elastic Cache with integrated monitoring service CloudWatch and the last one Configuration Management I read about the service (AWS Secret Manager) that I will use but didn&rsquo;t integrate yet.</p>
<p>That seems fair, have you faced some challenges learning AWS, I heard from my fellow developers that there are a few steeping curves in understanding the documentation and the services.</p>
<p>Somehow yes, as I don&rsquo;t know that much about AWS and the time isn&rsquo;t enough for learning and practising, I choose a tool to be abstract for me the underlying infrastructure for now, but I am willing to learn what happens in the background, so I can customize more.</p>
<p>What&rsquo;s the tool name?</p>
<p>AWS Copilot (the CTO typing the name, we need to hear the keyboard typing) it&rsquo;s an open source project &hellip;.(the CTO interrupt saying)</p>
<p>Hmm, I see, but wouldn&rsquo;t that add a new layer to learn, because most DevOps developers on the market will stick with IAC?</p>
<p>Yeah, I thought of that, I noticed that copilot works upon CloudFormation, which is an IAC tool for AWS and if you&rsquo;re asking why not use Terraform with built-in modules, I can tell with this method we will narrow in the future our range of search to DevOps with terraform knowledge as with the current situation we can teach our backend developers a few commands and that&rsquo;s enough to monitor the infrastructure.</p>
<p>Interesting, I&rsquo;m the type of technical guy, can you explain more about the solution?</p>
<p>Ok, can I open my laptop to show you</p>
<p>(developer unpacking the laptop sound)</p>
<p>Yeah, Sure</p>
<p>have you thought of opening a startup (the CTO also) (CTO show some interest in the developer)</p>
<p>(think few seconds) No, I don&rsquo;t think I am ready, but maybe a small side hustle</p>
<p>Okay, let me log into my AWS account (while typing)(the developer said) add the MFA code and here we go.</p>
<p>(the sound of the CTO moving to the chair next to the developer)</p>
<p>So, here is the CloudFormation dashboard, those are the stacks that copilot deployed, you can also identify them by tags, generally they have tags copilotenvironment and copilot-application, at the end if somehow copilot didn&rsquo;t meet our expectation or we couldn&rsquo;t customize it further we can just modify, extend and boom. Now let me show the commands to set up and deploy the services&hellip;..</p>
<p>You didn&rsquo;t deploy the app Yet, right? (while interrupting)</p>
<p>Not Yet</p>
<p>Ok (with notification sound on the phone), Continue</p>
<p>To set up infrastructure first, we need to run <code>copilot app init</code> then <code>copilot env init</code> after that copilot will ask us a few questions about the public and private subnets and the availability zone of the load balancer after we confirm that we see 3 Cloudformation stack has been created which define a few resources(VPC, Subnets, RouteTables,InternetGateway, and Cluster for Containers), finally I will be writing all the steps on notion.</p>
<p>And the dependencies? (CTO asked)</p>
<p>Yeah, I did my search on deploy RDS and ElasticCache, Copilot doesn&rsquo;t support either of them as a built-in command, but we can extend and create the services by ourselves and this is what I have done, the extended functionality support CloudFormation&rsquo;s files</p>
<p>Got It, but, hmm(take a few seconds to rephrase ), but I&rsquo;m worrying if we don&rsquo;t understand carefully and let copilot create the infrastructure, it may lead to creating unuseful services and you know we&rsquo;re short on money.</p>
<p>Yeah, I understand your concern but am willing to learn more about the architecture copilot created for us by that time I can see if copilot fits our needs else I remove it and advance my skills to manage by myself the rest of the infrastructure directly with cloud formation</p>
<p>That seems fair enough, Ok, here is what you gonna do in the next few days. After you finish deploying that config management thing, deploy the application on ECS, and handle it to the developers to try and check the performance, and what about the CI/CD</p>
<p>Copilot support it but didn&rsquo;t take a deep look into the documentation, I can deploy the application from my terminal, so let&rsquo;s tell the project manager whenever there is a pull request merged they notify me so I pull the code and push it for review</p>
<p>Noted, I will tell him</p>
]]></content:encoded>
    </item>
    <item>
      <title>GCP -&gt; AWS Migration: Stress Swallows You</title>
      <link>//localhost:1313/posts/stress-swallows-you/</link>
      <pubDate>Thu, 20 Apr 2023 15:36:32 +0100</pubDate>
      <guid>//localhost:1313/posts/stress-swallows-you/</guid>
      <description>3 days passes, and I&amp;rsquo;m struggling on the same bug, Am I looking at the wrong side of the window, I don&amp;rsquo;t know, I think the best way to understand is going back and examine every command line and line of code I wrote.
So at first, After I took the decision to use AWS copilot, I look at the task on JIRA, analyzed it carefully and saw the need to deploy application dependencies first, one of the dependencies is the database .</description>
      <content:encoded><![CDATA[<blockquote>
<p><em>3 days passes, and I&rsquo;m struggling on the same bug, Am I looking at the wrong side of the window, I don&rsquo;t know, I think the best way to understand is going back and examine every command line and line of code I wrote.</em></p>
</blockquote>
<p>So at first, After I took the decision to use AWS copilot, I look at the task on JIRA, analyzed it carefully and saw the need to deploy application dependencies first, one of the dependencies is the database <strong>.</strong> We have been using PostgresSQL V14, so we just need the same version on the dev environment.</p>
<p>I run through the documentation, to catch any command on how to deploy a database with underlying infrastructure(VPC, Subnet, Route Table, &hellip;). The first command I saw</p>
<pre><code>copilot init
</code></pre>
<p>It fulfils the need of creating the underlying infrastructure, but it requires an application ready to deploy, but this is not the case now. A few minutes after and stumbled upon another command with the description &ldquo;creates a new <a href="https://aws.github.io/copilot-cli/docs/concepts/environments/">environment</a> where your services will live.&rdquo;</p>
<pre><code>copilot env init
</code></pre>
<p>When I run the above command, it asked me to run <code>copilot app init</code> first. And here is the output of environment creation</p>
<!-- raw HTML omitted -->
<p>From my understanding of the output and manifest.yml file, it seems after running <code>copilot env deploy</code> it will create two public and private subnets on separate regions. So I proceeded with the command, and here is the output</p>
<!-- raw HTML omitted -->
<p>I googled a few terms I didn&rsquo;t understand like ECS, security groups, and DNS namespace to have basic knowledge of what happens in the background.</p>
<p>The following task was deploying the database and this is when things got trickier, now one of the features of copilot is a command to deploy storage services like database, file system&hellip; etc. It supports two types of databases DynamoDB, Aurora</p>
<p>Aurora seems a great option as it&rsquo;s fully compatible with PostgresSQL, so I tried to deploy a cluster using the following command</p>
<pre><code> copilot storage init -n cluster -t Aurora --lifecycle environment --engine PostgreSQL
</code></pre>
<p>At the same time, I opened Thunderbird and I messaged the CTO asking if it was ok deploying Aurora instead of an RDS. I went back to the command and I found</p>
<blockquote>
<p>Couldn&rsquo;t find any workloads associated with app noteapp, try initializing one: copilot [svc/job] init .<br>
✘ select a workload from noteapp : no workloads found in noteapp</p>
</blockquote>
<p>Well, the problem is obvious, I cannot deploy a storage service unless I create a service first and by service I mean containerized application.</p>
<p>I walked through the documentation again, and I found a magical feature that says &ldquo;Modeling Additional Environment Resources with AWS CloudFormation&rdquo;, this feature gave me the ability to deploy resources on an environment based.</p>
<p>That gave me goosebumps to understand CloudFormation, as it seems crucial in the next phases. The methodology was deploying a demo architecture to get comfortable with the services and the whole flow, I deployed one of the well-known architectures which is <strong>lambda function &amp; DynamoDB</strong> and here is my recap</p>
<p>CloudFormation file structure consists of 3 main blocks <strong>Parameters</strong> (Optional), <strong>Resources</strong> (Required), and <strong>Outputs</strong> (Optional).</p>
<ul>
<li><strong>Resources</strong> block encapsulate the services we need to deploy, Each service requires 2 properties <strong>Type, Properties</strong> and each service has different Properties, an example of that for <code>Lambda Function</code> there are <strong>Handler</strong> , <strong>Runtime</strong> , <strong>Code</strong> properties while on <code>DynamoDB::Table</code> there are different properties <strong>AttributeDefinitions</strong> , <strong>KeySchema</strong> , <strong>ProvisionedThroughput</strong></li>
</ul>
<!-- raw HTML omitted -->
<p>Now, AWS CLI has a built-in command for managing CloudFormation files, to create resources the first time the command is</p>
<pre><code>aws cloudformation create-stack --stack-name resource_stack --template-body file://cloudformation.yml --capabilities CAPABILITY_NAMED_IAM
</code></pre>
<p>and for update</p>
<pre><code>aws cloudformation update-stack --stack-name resource_stack --template-body file://cloudformation.yml --capabilities CAPABILITY_NAMED_IAM
</code></pre>
<p>An additional cool feature of AWS CloudFormation is the built-in managing dashboard where you can see your stacks and their status</p>
<!-- raw HTML omitted -->
<p>Then I started to think about integrating CloudFormation with Copilot until I looked through the window, and it was almost dark and my back was hurting, so I took the sign and went for a little bit of social life</p>
]]></content:encoded>
    </item>
    <item>
      <title>GCP -&gt; AWS Migration: Determination</title>
      <link>//localhost:1313/posts/determination/</link>
      <pubDate>Sun, 16 Apr 2023 16:05:46 +0100</pubDate>
      <guid>//localhost:1313/posts/determination/</guid>
      <description>You know that feeling ?, when you&amp;rsquo;re escaping a bad documentation, instead crawling around searching for a solution, and you find a snippet of code on Stack Overflow or Reddit, after you copy and paste it, it doesn&amp;rsquo;t work then your mind tells you &amp;ldquo;you need to change it a little bit&amp;rdquo;.
So you start changing the code to solve your problem, and guess what? A hell of a lot of new terminology and ideas enter your mind, and you start to get confused.</description>
      <content:encoded><![CDATA[<blockquote>
<p>You know that feeling ?, when you&rsquo;re escaping a bad documentation, instead crawling around searching for a solution, and you find a snippet of code on Stack Overflow or Reddit, after you copy and paste it, it doesn&rsquo;t work then your mind tells you &ldquo;you need to change it a little bit&rdquo;.<br>
So you start changing the code to solve your problem, and guess what? A hell of a lot of new terminology and ideas enter your mind, and you start to get confused. Well, I Hamza Bou Issa am in that state of mind.</p>
</blockquote>
<p>The last time I was left in &ldquo;Deploying RDS with copilot using CloudFormation&rdquo;, Yeah my approach to solving the problem is the same as before, typing a bunch of keywords and questions into Google, clicking on the first few links, if Stack Overflow then I detect responses with green mark and copy code, if it&rsquo;s an article, I find snippets and copy the ones that have RDS or DB on them</p>
<p>I took the time to understand CloudFormation file structure and a few resource types</p>
<p>At first, I found this snippet</p>
<pre><code># Set AWS template version
AWSTemplateFormatVersion: &quot;2010-09-09&quot;
# Set Parameters
Parameters:
  EngineVersion:
    Description: PostgreSQL version.
    Type: String
    Default: &quot;14.1&quot;
  SubnetIds:
    Description: Subnets
    Type: &quot;List&lt;AWS::EC2::Subnet::Id&gt;&quot;
  VpcId:
    Description: Insert your existing VPC id here
    Type: String

Resources:
  DBSubnetGroup:
    Type: &quot;AWS::RDS::DBSubnetGroup&quot;
    Properties:
      DBSubnetGroupDescription: !Ref &quot;AWS::StackName&quot;
      SubnetIds: !Ref SubnetIds

  DatabaseSecurityGroup:
    Type: &quot;AWS::EC2::SecurityGroup&quot;
    Properties:
      GroupDescription: The Security Group for the database instance.
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432

  DBInstance:
    Type: &quot;AWS::RDS::DBInstance&quot;
    Properties:
      AllocatedStorage: &quot;30&quot;
      DBInstanceClass: db.t4g.medium
      DBName: &quot;postgres&quot;
      DBSubnetGroupName: !Ref DBSubnetGroup
      Engine: postgres
      EngineVersion: !Ref EngineVersion
      MasterUsername: username
      MasterUserPassword: password
      StorageType: gp2
      MonitoringInterval: 0
      VPCSecurityGroups:
      - !Ref DatabaseSecurityGroup
</code></pre>
<p>The following code will create 3 resources: <strong>DbInstance</strong> , <strong>DatabaseSecurityGroup</strong> , <strong>DBSubnetGroup</strong> , From my understanding the connection between those resources is a Database need to be created on private <strong>Subnets(DBSubnetGroup)</strong> on the other side for the database to accept connection it needs a security group( <strong>DatabaseSecurityGroup</strong> ) which should be on the same <strong>VPC</strong> as the <strong>Subnets</strong></p>
<p>Now before I paste this code into <!-- raw HTML omitted -->environment/addons/rds.yml<!-- raw HTML omitted -->, I&rsquo;m going to remove the parameters as we have an alternate method of passing the <strong>SubnetIds</strong> and <strong>VpcId</strong>.</p>
<p>CloudFormation gives the ability to import resources from previously created stacks with <code>Fn::ImportValue</code> function. In this case, after I run <code>copilot env deploy --name test</code> . Copilot create 2 CloudFormation stacks</p>
<!-- raw HTML omitted -->
<p>The first stack is the interesting one, after we open on <strong>mycompany-app-test</strong> stack, we click on the Outputs panel, and it should show us the created resources with export names that can be imported on our RDS stack.</p>
<!-- raw HTML omitted -->
<p>The two interesting export names are <strong>mycompany-app-test-PrivateSubnets</strong> , <strong>mycompany-app-test-VpcId</strong> , let&rsquo;s refactor our rds.yml file and add them</p>
<pre><code># Set AWS template version
AWSTemplateFormatVersion: &quot;2010-09-09&quot;
# Set Parameters
Parameters:
  App:
    Type: String
    Description: Your application's name.
  Env:
    Type: String
    Description: The environment name your service, job, or workflow is being deployed
  Name:
    Type: String
    Description: The name of the service, job, or workflow being deployed.

Resources:
  DBSubnetGroup:
    Type: &quot;AWS::RDS::DBSubnetGroup&quot;
    Properties:
      DBSubnetGroupDescription: !Ref &quot;AWS::StackName&quot;
      SubnetIds:
        !Split [',', { 'Fn::ImportValue': !Sub '${App}-${Env}-PrivateSubnets'}]
  DatabaseSecurityGroup:
    Type: &quot;AWS::EC2::SecurityGroup&quot;
    Properties:
      GroupDescription: The Security Group for the database instance.
      VpcId:
        Fn::ImportValue: !Sub '${App}-${Env}-VpcId'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          CidrIp: 0.0.0.0/0

  DBInstance:
    Type: &quot;AWS::RDS::DBInstance&quot;
    Properties:
      AllocatedStorage: &quot;30&quot;
      DBInstanceClass: db.t4g.medium
      DBName: &quot;postgres&quot;
      DBSubnetGroupName: !Ref DBSubnetGroup
      Engine: postgres
      EngineVersion: &quot;14.1&quot;
      MasterUsername: username
      MasterUserPassword: password
      StorageType: gp2
      MonitoringInterval: 0
      VPCSecurityGroups:
      - !Ref DatabaseSecurityGroup
</code></pre>
<p>As you see, I removed the previous parameters and replace them with a few parameters <strong>App</strong> , <strong>Env</strong> , <strong>Name</strong> which is copilot required add-ons parameters. Also for SubnetIds I import PrivateSubnets and split it because it must be passed as separate values</p>
<p>After I run <code>copilot env deploy --name test</code> a nested stack will get created</p>
<!-- raw HTML omitted -->
<p>But how I&rsquo;m going to test if the database is working or accepting connection while it&rsquo;s not reachable on the public internet, well it seems I can create an ec2 instance on the public subnet and allow connection with the security group.</p>
<p>Here is the refactored code</p>
<pre><code># Set AWS template version
AWSTemplateFormatVersion: &quot;2010-09-09&quot;
# Set Parameters
Parameters:
  App:
    Type: String
    Description: Your application's name.
  Env:
    Type: String
    Description: The environment name your service, job, or workflow is being deployed to.

 
Resources:
  DBSubnetGroup:
    Type: &quot;AWS::RDS::DBSubnetGroup&quot;
    Properties:
      DBSubnetGroupDescription: !Ref &quot;AWS::StackName&quot;
      SubnetIds:
        !Split [',', { 'Fn::ImportValue': !Sub '${App}-${Env}-PrivateSubnets' }]
  
  DatabaseSecurityGroup:
    Type: &quot;AWS::EC2::SecurityGroup&quot;
    Properties:
      GroupDescription: The Security Group for the database instance.
      VpcId: 
        Fn::ImportValue:
          !Sub '${App}-${Env}-VpcId'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          CidrIp: 0.0.0.0/0
  
  DBInstance:
    Type: &quot;AWS::RDS::DBInstance&quot;
    Properties:
      AllocatedStorage: &quot;30&quot;
      DBInstanceClass: db.t4g.medium
      DBName: &quot;postgres&quot;
      DBSubnetGroupName: !Ref DBSubnetGroup
      Engine: postgres
      EngineVersion: &quot;14.1&quot;
      MasterUsername: username
      MasterUserPassword: password
      StorageType: gp2
      MonitoringInterval: 0
      VPCSecurityGroups:
        - !Ref DatabaseSecurityGroup
      Tags:
        - Key: Name
          Value: !Sub 'copilot-${App}-${Env}'

  NewKeyPair:
    Type: 'AWS::EC2::KeyPair'
    Properties:
      KeyName: !Sub ${App}-${Env}-EC2-RDS-KEYPAIR
      Tags:
        - Key: Name
          Value: !Sub 'copilot-${App}-${Env}'
  
  EC2SecuityGroup:
    Type: &quot;AWS::EC2::SecurityGroup&quot;
    Properties:
      GroupDescription: The Security Group for the ec2 instance.
      VpcId: 
        Fn::ImportValue:
          !Sub '${App}-${Env}-VpcId'
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub 'copilot-${App}-${Env}'
        
  Ec2Instance:
    Type: 'AWS::EC2::Instance'
    Properties:
      ImageId: ami-05e8e219ac7e82eba
      InstanceType: t2.micro
      KeyName: !Ref NewKeyPair
      SubnetId: !Select [&quot;0&quot;,!Split [',', { 'Fn::ImportValue': !Sub '${App}-${Env}-PublicSubnets' }]]
      SecurityGroupIds:
        - !Ref EC2SecuityGroup
      
      UserData: |
        #!/bin/bash
        sudo apt update
        sudo apt upgrade
        sudo apt install postgresql postgresql-contrib


      Tags:
        - Key: Name
          Value: !Sub 'copilot-${App}-${Env}'
      


Outputs:
  ServerPublicDNS:
    Description: &quot;Public DNS of EC2 instance&quot;
    Value: !GetAtt Ec2Instance.PublicDnsName

  DatabaseEndpoint:
    Description: &quot;Connection endpoint for the database&quot;
    Value: !GetAtt DBInstance.Endpoint.Address
</code></pre>
<p>A few things to notice, I added an Ec2Instance on a public subnet, a security group that allows only ssh port (22), meanwhile, the ImageId, InstanceType property are more tied to the region you&rsquo;re deploying to, I am using eu-west-3(I&rsquo;m not a French guy -_-). NewKeyPair is the ssh key to log into EC2, and finally the Outputs section for getting the EC2 instance and Database connection URL</p>
<p>I rerun <code>copilot env deploy --name test</code> , wait for the stack to update, before connecting to ec2 an ssh file must be downloaded, the ssh key pair will be saved on AWS Parameter Store, here are the following steps to download it</p>
<pre><code>aws ec2 describe-key-pairs --filters Name=key-name,Values=mycompany-app-test-E
</code></pre>
<p>The above command output.</p>
<pre><code>key-05abb699beEXAMPLE
</code></pre>
<p>and to save the ssh key value</p>
<pre><code>aws ssm get-parameter --name /ec2/keypair/key-05abb699beEXAMPLE --with-decrypt
</code></pre>
<p>Now, After I get the ssh file, try to connect to the server</p>
<pre><code>ssh -i new-key-pair.pem ubuntu@ec2-host
</code></pre>
<p>I try to connect to RDS</p>
<pre><code>psql -U username -d postgres -h database_host
</code></pre>
<!-- raw HTML omitted -->
]]></content:encoded>
    </item>
  </channel>
</rss>
